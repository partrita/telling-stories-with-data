---
engine: knitr
---

# 데이터로 이야기하기 {#sec-introduction}

::: {.callout-note}
Chapman and Hall/CRC는 2023년 7월에 이 책을 출판했습니다. [여기](https://www.routledge.com/Telling-Stories-with-Data-With-Applications-in-R/Alexander/p/book/9781032134772)에서 구매할 수 있습니다. 이 온라인 버전에는 인쇄된 내용에 대한 몇 가지 업데이트가 있습니다.
:::

**선행 학습**

- *셀 수 없는 것을 세다*, [@keyes2019] 읽기
  - 이 글은 세상을 데이터로 바꾸는 것의 어려움에 대해 논합니다.
- *부엌 조리대 관측소*, [@kieranskitchen] 읽기
  - 데이터가 숨기고 드러내는 것에 대한 논의.
- *6분 만에 배우는 데이터 과학 윤리*, [@register2020] 시청하기
  - 이 비디오는 윤리와 데이터 과학을 건설적인 방식으로 통합합니다.
- *코드란 무엇인가?*, [@nottomford] 읽기
  - 이 글은 코드의 역할에 대한 개요를 제공하며, 처음 세 섹션에 집중해야 합니다.

## 이야기하기에 관하여

많은 부모들이 자녀가 태어나면 가장 먼저 하는 일 중 하나는 이야기를 읽어주는 것입니다. 그렇게 함으로써 그들은 수천 년 동안 이어져 온 전통을 이어갑니다. 신화, 우화, 동화는 우리 주변 어디에서나 보고 들을 수 있습니다. 그것들은 재미있을 뿐만 아니라 우리가 세상에 대해 배울 수 있게 해줍니다. 에릭 칼의 *매우 배고픈 애벌레*는 데이터를 다루는 세계와는 상당히 거리가 멀어 보일 수 있지만, 유사점이 있습니다. 둘 다 이야기를 하고 지식을 전달하는 것을 목표로 합니다.

데이터를 사용할 때 우리는 설득력 있는 이야기를 하려고 노력합니다. 그것은 선거 예측만큼 흥미로울 수도 있고, 인터넷 광고 클릭률 증가만큼 평범할 수도 있고, 질병의 원인을 찾는 것만큼 심각할 수도 있고, 농구 경기 예측만큼 재미있을 수도 있습니다. 어떤 경우든 핵심 요소는 동일합니다. 20세기 초 영국 작가 E. M. 포스터는 모든 소설에 공통적인 측면을 이야기, 인물, 줄거리, 환상, 예언, 패턴, 리듬으로 묘사했습니다[@forster]. 마찬가지로, 설정에 관계없이 데이터로 이야기를 할 때 공통적인 관심사가 있습니다.

1. 데이터셋은 무엇인가? 누가 데이터셋을 생성했고 왜 생성했는가?
2. 데이터셋의 기반이 되는 프로세스는 무엇인가? 해당 프로세스를 고려할 때 데이터셋에서 누락되었거나 제대로 측정되지 않은 것은 무엇인가? 다른 데이터셋이 생성될 수 있었고, 만약 그렇다면 우리가 가진 것과 얼마나 다를 수 있었는가?
3. 데이터셋은 무엇을 말하려고 하며, 어떻게 그렇게 말하게 할 수 있는가? 그 밖에 무엇을 말할 수 있는가? 이들 중에서 어떻게 결정하는가?
4. 이 데이터셋에서 다른 사람들이 무엇을 보기를 바라는가, 그리고 어떻게 그들을 설득할 수 있는가? 그들을 설득하기 위해 얼마나 많은 작업을 해야 하는가?
5. 이 데이터셋과 관련된 프로세스 및 결과에 의해 누가 영향을 받는가? 그들이 데이터셋에 어느 정도 표현되어 있으며, 분석에 참여했는가?

과거에는 데이터로 이야기를 하는 특정 요소가 더 쉬웠습니다. 예를 들어, 실험 설계는 농업 및 의학, 물리학, 화학 분야에서 길고 견고한 전통을 가지고 있습니다. 스튜던트의 t-분포는 1900년대 초 맥주 제조업체인 기네스에서 일했던 화학자 윌리엄 실리 고셋에 의해 확인되었습니다[@boland1984biographical]. 그가 맥주를 무작위로 샘플링하고 한 번에 한 가지 측면을 변경하는 것은 비교적 간단했을 것입니다.

오늘날 우리가 사용하는 통계 방법의 많은 기본 사항은 그러한 환경에서 개발되었습니다. 그러한 상황에서는 일반적으로 통제 그룹을 설정하고 무작위화하는 것이 가능했으며 윤리적 우려도 적었습니다. 그 결과 데이터로 만들어진 이야기는 상당히 설득력이 있었을 것입니다.

불행히도, 통계 방법이 적용되는 설정의 다양성을 고려할 때 오늘날에는 이러한 것이 거의 적용되지 않습니다. 반면에 우리는 많은 이점을 가지고 있습니다. 예를 들어, 우리는 잘 개발된 통계 기법, 대규모 데이터셋에 대한 더 쉬운 접근, R 및 Python과 같은 오픈 소스 언어를 가지고 있습니다. 그러나 전통적인 실험을 수행하는 것이 어렵다는 것은 설득력 있는 이야기를 하기 위해 다른 측면에도 의존해야 함을 의미합니다.

## 워크플로 구성 요소

데이터로 이야기를 전달하는 데 필요한 워크플로에는 5가지 핵심 구성 요소가 있습니다.

1. 최종 목표를 **계획**하고 스케치합니다.
2. 시뮬레이션된 데이터를 **시뮬레이션**하고 고려합니다.
3. 실제 데이터를 **수집**하고 준비합니다.
4. 실제 데이터를 **탐색**하고 이해합니다.
5. 수행한 작업과 발견한 내용을 **공유**합니다.

우리는 **최종 목표를 계획하고 스케치하는 것**부터 시작합니다. 이렇게 하면 우리가 가고 싶은 곳에 대해 신중하게 생각할 수 있기 때문입니다. 이는 우리가 상황을 깊이 고려하도록 강요하고, 집중적이고 효율적으로 유지하며, 범위蔓延을 줄이는 데 도움이 됩니다. 루이스 캐럴의 *이상한 나라의 앨리스*에서 앨리스는 체셔 고양이에게 어느 길로 가야 하는지 묻습니다. 체셔 고양이는 앨리스가 어디로 가고 싶은지 물어봄으로써 대답합니다. 그리고 앨리스가 어딘가에 도착하기만 하면 상관없다고 대답하자 체셔 고양이는 "충분히 오래 걸으면" 항상 어딘가에 도착할 것이기 때문에 방향은 중요하지 않다고 말합니다. 우리 경우의 문제는 일반적으로漫然히 오래 걸을 여유가 없다는 것입니다. 최종 목표를 변경해야 할 수도 있지만, 이것이 신중하고 합리적인 결정이어야 한다는 것이 중요합니다. 그리고 그것은 초기 목표가 주어졌을 때만 가능합니다. 이것으로부터 많은 가치를 얻기 위해 너무 많은 시간을 할애할 필요는 없습니다. 종종 종이와 펜으로 10분이면 충분합니다.

다음 단계는 **데이터를 시뮬레이션**하는 것입니다. 그렇게 하면 세부 사항에 집중하게 되기 때문입니다. 데이터셋의 클래스와 예상되는 값의 분포에 집중하게 되므로 데이터셋 정리 및 준비에 도움이 됩니다. 예를 들어, 연령대가 정치적 선호도에 미치는 영향에 관심이 있다면 연령대 변수는 "18-29", "30-44", "45-59", "60+"의 네 가지 가능한 값을 가진 요인이 될 것으로 예상할 수 있습니다. 시뮬레이션 프로세스는 실제 데이터셋이 충족해야 하는 명확한 특징을 제공합니다. 이러한 특징을 사용하여 데이터 정리 및 준비를 안내하는 테스트를 정의할 수 있습니다. 예를 들어, 실제 데이터셋에서 해당 네 가지 값이 아닌 연령대를 확인할 수 있습니다. 해당 테스트를 통과하면 연령대 변수에 예상되는 값만 포함되어 있다고 확신할 수 있습니다.

데이터 시뮬레이션은 통계 모델링으로 전환할 때도 중요합니다. 해당 단계에 있을 때 우리는 모델이 데이터셋에 있는 내용을 반영하는지 여부에 관심이 있습니다. 문제는 실제 데이터셋을 모델링하는 데 바로 착수하면 모델에 문제가 있는지 여부를 알 수 없다는 것입니다. 우리는 기본 데이터 생성 프로세스를 정확히 알 수 있도록 처음에 데이터를 시뮬레이션합니다. 그런 다음 시뮬레이션된 데이터셋에 모델을 적용합니다. 입력한 내용을 얻으면 모델이 적절하게 수행되고 있음을 알 수 있으며 실제 데이터셋으로 전환할 수 있습니다. 시뮬레이션된 데이터에 대한 초기 적용 없이는 모델에 대한 확신을 갖기가 더 어려울 것입니다.

시뮬레이션은 종종 저렴합니다. 현대 컴퓨팅 리소스와 프로그래밍 언어를 고려하면 거의 무료입니다. 그리고 빠릅니다.\index{simulation} 그것은 "상황에 대한 친밀한 느낌"을 제공합니다[@hamming1996, p. 239]. 필수적인 것만 포함하는 시뮬레이션부터 시작하여 작동하도록 한 다음 복잡하게 만드십시오.

우리가 관심 있는 **데이터를 획득하고 준비하는 것**은 워크플로에서 종종 간과되는 단계입니다. 이는 가장 어려운 단계 중 하나일 수 있고 많은 결정을 내려야 하기 때문에 놀랍습니다. 점점 더 많은 연구의 대상이 되고 있으며, 이 단계에서 내린 결정이 통계 결과에 영향을 미칠 수 있다는 것이 밝혀졌습니다[@huntington2021influence; @AhadyDolatsara2021; @Gould2023].

워크플로의 이 단계에서는 약간 압도감을 느끼는 것이 일반적입니다. 일반적으로 우리가 얻을 수 있는 데이터는 우리를 약간 두렵게 만듭니다. 너무 적을 수도 있고, 이 경우 통계 기계를 어떻게 작동시킬 수 있을지 걱정합니다. 또는 반대의 문제가 있을 수도 있고, 그렇게 많은 양의 데이터를 어떻게 처리해야 할지 걱정할 수도 있습니다.

> 어쩌면 우리 삶의 모든 용들은 우리가 한 번만이라도 아름다움과 용기를 가지고 행동하기를 기다리는 공주들일지도 모릅니다. 어쩌면 우리를 두렵게 하는 모든 것은 가장 깊은 본질에서 우리의 사랑을 원하는 무력한 것일지도 모릅니다.
>
> @rilke

워크플로의 이 단계에서 편안함을 개발하면 나머지 부분이 잠금 해제됩니다. 설득력 있는 이야기를 하는 데 필요한 데이터셋이 거기에 있습니다. 그러나 조각가처럼 우리는 필요하지 않은 모든 것을 반복적으로 제거한 다음 필요한 것을 모양을 만들어야 합니다.

데이터셋이 있으면 해당 데이터셋의 특정 관계를 **탐색하고 이해**하려고 합니다. 일반적으로 기술 통계로 프로세스를 시작한 다음 통계 모델로 이동합니다. 데이터의 의미를 이해하기 위해 통계 모델을 사용하는 것은 편향이 없거나 "진실"이 아닙니다. 그들은 우리가 하라고 하는 대로 합니다.\index{model!role} 데이터로 이야기를 할 때 통계 모델은 그래프와 표를 사용하는 것과 같은 방식으로 데이터셋을 탐색하는 데 사용하는 도구이자 접근 방식입니다. 그것들은 우리에게 명확한 결과를 제공하는 것이 아니라 특정 방식으로 데이터셋을 더 명확하게 이해할 수 있게 해줍니다.

워크플로의 이 단계에 도달할 때쯤이면 모델은 기본 데이터 생성 프로세스 유형만큼이나 초기 단계, 특히 획득 및 정리 단계에서 내려진 결정을 반영하게 됩니다. 정교한 모델러는 자신의 통계 모델이 빙산의 일각과 같다는 것을 알고 있습니다. 즉, 그들은 대부분이 아래에 있는 것, 이 경우에는 데이터에 기반을 두고 있으며 그것 때문에만 가능합니다. 그러나 전체 데이터 과학 워크플로의 전문가가 모델링을 사용할 때, 그들은 얻은 결과가 누구의 데이터가 중요한지에 대한 선택, 데이터를 측정하고 기록하는 방법에 대한 결정, 그리고 데이터가 특정 워크플로에 사용 가능해지기 훨씬 전에 세상이 있는 그대로를 반영하는 기타 측면 때문이라는 것을 인식합니다.\index{data science!workflow}

마지막으로, 우리가 한 일과 발견한 것을 가능한 한 높은 충실도로 **공유**해야 합니다. 당신만이 아는 지식에 대해 이야기하는 것은 당신을 박식하게 만들지 않으며, 여기에는 "과거의 당신"만이 아는 지식도 포함됩니다. 의사소통할 때, 우리가 내린 결정, 왜 그렇게 했는지, 우리의 발견, 그리고 우리 접근 방식의 약점에 대해 명확해야 합니다. 우리는 중요한 것을 밝혀내는 것을 목표로 하므로 처음에는 모든 것을 적어야 하지만, 이 서면 의사소통은 나중에 다른 형태의 의사소통으로 보완될 수 있습니다. 이 워크플로에서 내려야 할 결정이 너무 많아서 처음부터 끝까지 모든 것에 대해 공개해야 합니다. 이것은 통계 모델링과 그래프 및 표 작성뿐만 아니라 모든 것을 의미합니다. 이것이 없으면 데이터를 기반으로 한 이야기는 신뢰성이 부족합니다.

세상은 모든 것이 신중하고 현명하게 평가되는 합리적인 능력주의 사회가 아닙니다. 대신, 우리는 경험을 바탕으로 지름길, 편법, 경험적 방법을 사용합니다. 불분명한 의사소통은 최고의 작업조차도 무용지물로 만들 것입니다. 왜냐하면 그것은 철저하게 다루어지지 않을 것이기 때문입니다. 의사소통에는 최소한의 기준이 있지만, 그것이 얼마나 인상적일 수 있는지에 대한 상한선은 없습니다. 잘 짜여진 워크플로의 정점일 때, 그것은 심지어 어떤 *스프레차투라*, 즉 연구된 부주의함을 얻을 수도 있습니다. 그러한 숙달을 이루려면 수년간의 노력이 필요합니다.

## 데이터로 이야기하기

데이터를 기반으로 한 설득력 있는 이야기는 약 10~20페이지로 전달할 수 있습니다. 이보다 적으면 일부 세부 사항이 너무 부족할 가능성이 높습니다. 그리고 훨씬 더 많이 쓰는 것은 쉽지만, 종종 약간의 성찰을 통해 간결하게 만들거나 여러 이야기를 분리할 수 있습니다.

전통적인 실험을 수행할 수 없을 때에도 설득력 있는 이야기를 하는 것이 가능합니다. 이러한 접근 방식은 "빅 데이터"(만병통치약이 아님 [@meng2018statistical; @Bradley2021])에 의존하는 대신 사용 가능한 데이터를 더 잘 활용하는 데 의존합니다. 연구와 독립적인 학습, 이론과 응용의 조화, 실용적인 기술, 정교한 워크플로, 그리고 자신이 모르는 것에 대한 이해가 결합되면 종종 지속적인 지식을 창출하기에 충분합니다.

데이터를 기반으로 한 최고의 이야기는 여러 분야에 걸쳐 있는 경향이 있습니다. 그들은 필요한 분야에서 무엇이든 가져오지만 거의 항상 통계학,\index{statistics} 소프트웨어 공학,\index{software engineering} 경제학,\index{economics} 공학\index{engineering} (몇 가지만 언급하자면)을 활용합니다. 따라서 종단 간 워크플로에는 이러한 분야의 기술 조합이 필요합니다. 이러한 기술을 배우는 가장 좋은 방법은 실제 데이터를 사용하여 다음과 같은 연구 프로젝트를 수행하는 것입니다.

- 연구 질문을 개발합니다.
- 관련 데이터셋을 확보하고 정리합니다.
- 해당 질문에 답하기 위해 데이터를 탐색합니다. 그리고
- 의미 있는 방식으로 소통합니다.

데이터로 설득력 있는 이야기를 하는 핵심 요소는 다음과 같습니다.

1. 소통.
2. 재현성.
3. 윤리학.
4. 질문.
5. 측정.
6. 데이터 수집.
7. 데이터 정제.
8. 탐색적 데이터 분석.
9. 모델링.
10. 확장.

이러한 요소들은 몇 가지 다른 범주 내에서 고려될 수 있습니다. 여기에는 좋은 연구 수행(윤리 및 질문), 신뢰할 수 있는 답변 도출(측정, 수집, 정제, 탐색적 데이터 분석 및 모델링), 설득력 있는 설명 생성(소통, 재현성 및 확장)이 포함됩니다. 이러한 요소들은 워크플로가 구축되는 기반입니다(@fig-iceberg).

![워크플로는 다양한 요소 위에 구축됩니다](figures/iceberg.png){#fig-iceberg width=70% fig-align="center"}

이것은 숙달해야 할 것이 많지만, **소통**이 가장 중요합니다. 잘 전달된 간단한 분석은 제대로 전달되지 않은 복잡한 분석보다 더 가치가 있습니다. 후자는 다른 사람들이 이해하거나 신뢰할 수 없기 때문입니다. 명확한 소통의 부족은 때때로 연구자가 무슨 일이 일어나고 있는지, 심지어 자신이 무엇을 하고 있는지 이해하지 못하는 것을 반영합니다. 따라서 분석 수준은 데이터셋, 도구, 작업 및 기술 수준과 일치해야 하지만, 명확성과 복잡성 사이에서 절충이 필요한 경우 명확성 쪽으로 기우는 것이 합리적일 수 있습니다.

명확한 의사소통은 청중을 함께 데려가는 방식으로 표, 그래프, 모델의 도움을 받아 평이한 언어로 작성하는 것을 의미합니다. 무엇을 했고 왜 했는지, 그리고 무엇을 발견했는지 명시하는 것을 의미합니다. 최소한의 기준은 다른 사람이 독립적으로 당신이 한 일을 하고 당신이 발견한 것을 찾을 수 있을 정도로 수행되는 것입니다. 한 가지 과제는 데이터에 몰입할수록 처음 접했을 때 어땠는지 기억하기 어려울 수 있다는 것입니다. 그러나 대부분의 청중은 거기서부터 시작할 것입니다. 적절한 수준의 미묘함과 세부 사항을 제공하는 법을 배우는 것은 어려울 수 있지만 청중의 이익을 위해 글쓰기에 집중하면 더 쉬워집니다.

**재현성**은 세상에 대한 지속적인 지식을 창출하는 데 필요합니다. 이는 수행된 모든 것, 즉 종단 간 모든 것을 독립적으로 다시 수행할 수 있음을 의미합니다. 이상적으로는 자율적인 종단 간 재현성이 가능해야 합니다. 누구나 코드, 데이터 및 환경을 얻어 수행된 모든 것을 확인할 수 있습니다[@heil2021reproducibility]. 코드에 대한 무제한 액세스는 거의 항상 가능합니다. 데이터에 대해서도 이것이 기본 기대치이지만 항상 합리적인 것은 아닙니다. 예를 들어, 심리학 연구에는 개인을 식별할 수 있는 소규모 샘플이 있을 수 있습니다. 한 가지 방법은 유사한 속성을 가진 시뮬레이션된 데이터를 공개적으로 공유하고, 적절한 *선의*가 주어지면 실제 데이터에 액세스할 수 있는 프로세스를 정의하는 것입니다. 통계 모델은 일반적으로 광범위한 수동 검사를 받습니다. 재현성의 또 다른 측면은 유사하게 광범위한 자동화된 테스트를 포함해야 한다는 것입니다.

**윤리**에 대한 적극적인 고려가 필요합니다. 왜냐하면 데이터셋은 아마도 인간과 관련이 있기 때문입니다. 이것은 다음과 같은 것들을 고려하는 것을 의미합니다: 누가 데이터셋에 있고, 누가 빠져 있으며, 왜 빠져 있는가?\index{ethics!missing data}\index{data!ethics of missing data} 우리의 이야기가 과거를 어느 정도까지 영속시킬 것인가? 그리고 이것이 일어나야 할 일인가? 데이터셋이 인간과 관련이 없더라도 이야기는 아마도 인간에 의해 만들어지고 있으며, 우리는 거의 모든 것에 영향을 미칩니다. 이것은 우리가 환경 영향과 불평등에 대한 우려를 가지고 데이터를 윤리적으로 사용할 책임이 있음을 의미합니다.

윤리에 대한 많은 정의가 있지만, 데이터로 이야기를 하는 경우 최소한 데이터셋의 전체 맥락을 고려하는 것을 의미합니다[@datafeminism2020]. 법학에서 법에 대한 텍스트적 접근 방식은 인쇄된 대로 법의 단어를 문자 그대로 고려하는 것을 의미하는 반면, 목적론적 접근 방식은 법이 더 넓은 맥락에서 해석되는 것을 의미합니다. 데이터로 이야기를 하는 윤리적 접근 방식은 후자의 접근 방식을 채택하고 우리 세계, 따라서 우리 데이터를 형성하는 사회적, 문화적, 역사적, 정치적 힘을 고려하는 것을 의미합니다[@crawford].\index{data science!ethics}

호기심은 데이터셋과 관련 프로세스를 적절한 범위까지 탐색하려는 내적 동기를 제공합니다. **질문**은 질문을 낳는 경향이 있으며, 데이터셋을 이해하는 과정이 진행됨에 따라 일반적으로 개선되고 정제됩니다. 종종 가르치는 가설 검증의 일반적인 포퍼적 접근 방식과는 대조적으로, 질문은 일반적으로 지속적이고 진화하는 과정을 통해 개발됩니다[@franklin2005exploratory]. 초기 질문을 찾는 것은 어려울 수 있습니다. 연구 질문을 합리적으로 이용 가능한 측정 가능한 변수로 조작하는 것은 특히 어렵습니다. 관심 분야를 선택하는 것이 도움이 될 수 있으며, 특정 질문으로 발전시키려는 의도로 광범위한 주장을 스케치하고 마지막으로 두 가지 다른 영역을 통합하는 것도 도움이 될 수 있습니다.

실제 데이터의 복잡함 속에서 편안함과 용이함을 개발하는 것은 데이터가 업데이트될 때마다 새로운 질문을 할 수 있게 된다는 것을 의미합니다. 그리고 데이터셋을 자세히 알면 예상치 못한 그룹이나 값이 나타나 해당 분야 전문가와 협력하여 이해할 수 있게 됩니다. 다양한 분야에 걸쳐 지식 기반을 개발하여 일종의 "하이브리드"가 되는 것은 특히 가치가 있으며, 처음에는 어리석은 질문을 할 가능성에 대해 편안해지는 것도 마찬가지입니다.

**측정**과 **데이터 수집**은 우리 세상이 어떻게 데이터가 될 것인지를 결정하는 것입니다. 그것들은 어렵습니다.\index{measurement}\index{data!collection} 세상은 너무나 활기차서 일관되게 측정하고 수집할 수 있는 것으로 축소하기가 어렵습니다. 예를 들어, 누군가의 키를 생각해 보십시오. 우리는 아마도 키를 재기 전에 신발을 벗어야 한다는 데 모두 동의할 것입니다. 그러나 우리의 키는 하루 동안 변합니다. 그리고 줄자로 누군가의 키를 재는 것은 레이저를 사용하는 것과 다른 결과를 줄 것입니다. 따라서 사람 간 또는 시간 경과에 따른 키를 비교하는 경우 매일 같은 시간에 같은 방법을 사용하여 측정하는 것이 중요해집니다. 그러나 그것은 금방 실행 불가능해집니다. 그리고 이것은 이러한 데이터의 데이터베이스 표현에 관한 문제를 제쳐두고 있습니다[@kentheight].

우리가 관심 있는 대부분의 질문은 키보다 더 복잡한 데이터를 사용할 것입니다. 누군가가 얼마나 슬픈지 어떻게 측정합니까? 고통을 어떻게 측정합니까? 무엇을 측정하고 어떻게 측정할지 누가 결정합니까? 세상을 가치로 축소하고 이것들을 비교할 수 있다고 생각하는 데는 어떤 오만함이 필요합니다. 궁극적으로 우리는 그렇게 해야 하지만, 측정할 대상을 일관되게 정의하기는 어렵습니다. 이 과정은 가치 중립적이지 않습니다. 이 잔인한 축소를 합리적으로 받아들이는 유일한 방법은 우리가 측정하고 수집하는 것을 깊이 이해하고 존중하는 것입니다. 핵심 본질은 무엇이며, 무엇을 제거할 수 있습니까?

20세기 스페인 화가 파블로 피카소는 단 하나의 선으로 동물의 윤곽을 묘사한 일련의 그림을 가지고 있습니다(@fig-lumpthedog). 단순함에도 불구하고 우리는 어떤 동물이 묘사되고 있는지 인식합니다. 그림은 그 동물이 고양이가 아닌 개라는 것을 알기에 충분합니다. 이것이 개가 아픈지 여부를 판단하는 데 사용될 수 있을까요? 아마도 아닐 것입니다. 우리는 아마도 다른 묘사를 원할 것입니다. 어떤 것을 측정해야 하는지, 그리고 우리가 고려하기로 결정한 것들 중에서 어떤 특징을 측정하고 수집하고 어떤 것을 무시해야 하는지에 대한 결정은 맥락과 목적에 따라 달라집니다.

![파블로 피카소의 이 그림은 단 한 줄이지만 분명히 개입니다](figures/lump.png){#fig-lumpthedog width=70% fig-align="center"}

**데이터 정제 및 준비**는 데이터 사용의 중요한 부분입니다.\index{data!cleaning} 사용 가능한 데이터를 우리가 사용할 수 있는 데이터셋으로 마사지해야 합니다. 이를 위해서는 많은 결정을 내려야 합니다. 데이터 정제 및 준비 단계는 중요하며 다른 어떤 단계만큼이나 많은 관심과 주의를 기울일 가치가 있습니다.

@kennedy2020using에 따르면, 성별이라는 잠재적으로 민감한 주제에 대한 정보를 수집한 설문 조사를 생각해 보십시오. 이 설문 조사는 "남성", "여성", "응답하지 않음", "기타"의 네 가지 옵션을 사용했으며, "기타"는 공개 텍스트 상자로 이어졌습니다.\index{gender!surveys} 해당 데이터셋을 보면 대부분의 응답이 "남성" 또는 "여성"임을 알 수 있습니다. "응답하지 않음"에 대해 어떻게 처리할지 결정해야 합니다. 데이터셋에서 이를 삭제하면 이러한 응답자를 적극적으로 무시하는 것입니다. 삭제하지 않으면 분석이 더 복잡해집니다. 마찬가지로 공개 텍스트 응답을 어떻게 처리할지 결정해야 합니다. 다시 말하지만, 이러한 응답을 삭제할 수 있지만 이는 일부 응답자의 경험을 무시하는 것입니다. 또 다른 옵션은 이를 "응답하지 않음"과 병합하는 것이지만, 이는 응답자가 해당 옵션을 구체적으로 선택하지 않았기 때문에 응답자를 무시하는 것을 보여줍니다.

많은 데이터 정리 및 준비 상황에서 쉽거나 항상 올바른 선택은 없습니다. 상황과 목적에 따라 다릅니다. 데이터 정리 및 준비에는 이와 같은 많은 선택이 포함되며, 다른 사람들이 무엇을 했고 왜 했는지 이해할 수 있도록 모든 단계를 기록하는 것이 중요합니다. 데이터는 결코 스스로 말하지 않습니다. 데이터는 데이터를 정리하고 준비한 복화술사의 꼭두각시입니다.

데이터셋의 모양과 느낌을 이해하는 과정을 **탐색적 데이터 분석**(EDA)이라고 합니다.\index{탐색적 데이터 분석} 이것은 개방형 프로세스입니다. 공식적으로 모델링하기 전에 데이터셋의 모양을 이해해야 합니다. EDA 프로세스는 요약 통계, 그래프, 표를 생성하고 때로는 일부 모델링까지 포함하는 반복적인 프로세스입니다. 공식적으로 끝나지 않는 프로세스이며 다양한 기술이 필요합니다.

EDA가 어디에서 끝나고 공식적인 통계 모델링이 시작되는지 구분하기는 어렵습니다. 특히 신념과 이해가 어떻게 발전하는지 고려할 때 그렇습니다[@Hullman2021Designing]. 그러나 핵심적으로는 데이터에서 시작하여 데이터에 몰입하는 것을 포함합니다[@Cook2021Foundation]. EDA는 일반적으로 최종 이야기에 명시적으로 포함되지 않습니다. 그러나 우리가 하는 이야기를 이해하는 방식에 중심적인 역할을 합니다. EDA 중에 수행된 모든 단계를 기록하고 공유하는 것이 중요합니다.

**통계 모델링**은 길고 견고한 역사를 가지고 있습니다.\index{model!building} 통계 지식은 수백 년에 걸쳐 구축되었습니다.\index{statistics} 통계는 일련의 건조한 정리와 증명이 아니라 세상을 탐구하는 방법입니다. 그것은 "외국어 또는 대수학 지식과 유사합니다. 언제 어떤 상황에서도 유용할 수 있습니다."[@bowley, p. 4]. 통계 모델은 만약-이렇다면-저렇다는 식으로 순진하게 따라야 할 레시피가 아니라 데이터를 이해하는 방법입니다[@islr]. 모델링은 일반적으로 데이터에서 통계적 패턴을 추론하는 데 필요합니다. 더 공식적으로, 통계적 추론은 "데이터를 사용하여 데이터를 생성한 분포를 추론하는 프로세스"입니다[@wasserman p. 87].

통계적 유의성은 과학적 유의성과 동일하지 않으며, 우리는 지배적인 패러다임이었던 것의 대가를 깨닫고 있습니다. 데이터에 임의의 합격/불합격 통계 테스트를 사용하는 것은 거의 적절하지 않습니다. 대신, 통계 모델링의 적절한 사용은 일종의 반향 정위와 같습니다. 우리는 모델에서 우리에게 돌아오는 것을 듣고 세상의 모양에 대해 배우는 데 도움을 받지만, 그것이 세상의 한 가지 표현일 뿐이라는 것을 인식합니다.

R 및 Python과 같은 프로그래밍 언어 사용은\index{R}\index{Python} 작업을 신속하게 **확장**할 수 있게 해줍니다. 이는 입력과 출력 모두를 의미합니다. 10개의 관찰값을 고려하는 것이 1,000개 또는 심지어 1,000,000개를 고려하는 것만큼이나 쉽습니다. 이를 통해 우리 이야기가 어느 정도까지 적용되는지 더 빨리 알 수 있습니다. 또한 우리 결과물은 한 사람이 소비하는 것만큼이나 10명 또는 100명이 쉽게 소비할 수 있습니다. 애플리케이션 프로그래밍 인터페이스(API)를 사용하면 우리 이야기가 초당 수천 번 고려될 수도 있습니다.

## 우리 세상은 어떻게 데이터가 되는가?

> 에딩턴의 유명한 이야기가 있습니다. 어떤 사람들이 그물로 바다에서 낚시를 하러 갔습니다. 그들이 잡은 물고기의 크기를 조사한 후, 그들은 바다에는 물고기의 최소 크기가 있다고 결정했습니다! 그들의 결론은 현실이 아니라 사용된 도구에서 비롯되었습니다.
>
> @hamming1996 [p. 177]

어느 정도 우리는 시간을 낭비하고 있습니다. 우리는 세상의 완벽한 모델을 가지고 있습니다. 바로 세상 그 자체입니다! 하지만 너무 복잡합니다. 모든 것이 그것에 영향을 미치는 셀 수 없는 요인에 의해 어떻게 영향을 받는지 완벽하게 안다면, 동전 던지기, 주사위 굴리기, 그리고 겉보기에 무작위적인 다른 모든 과정을 매번 완벽하게 예측할 수 있을 것입니다. 하지만 우리는 할 수 없습니다. 대신, 우리는 그럴듯하게 측정 가능한 것으로 단순화해야 하며, 그것이 우리가 데이터로 정의하는 것입니다. 우리의 데이터는 그것들이 파생된 지저분하고 복잡한 세상의 단순화입니다.

"그럴듯하게 측정 가능한" 것에는 다양한 근사치가 있습니다. 따라서 데이터셋은 항상 선택의 결과입니다.\index{data!as the result of choices} 우리는 그것들이 당면한 작업에 대해 그럼에도 불구하고 합리적인지 여부를 결정해야 합니다. 우리는 통계 모델을 사용하여 데이터에 대해 깊이 생각하고, 탐색하고, 바라건대 더 잘 이해하는 데 도움을 받습니다.

많은 통계학은 우리가 가진 데이터를 철저히 고려하는 데 중점을 둡니다.\index{statistics} 이는 우리 데이터가 농업, 천문학 또는 물리 과학에서 비롯되었을 때 적절했습니다. 이것은 비인간적 맥락에서 체계적 편향이 존재하거나 영향을 미칠 수 없다는 것을 말하는 것이 아니라, 데이터 과학의 부상과 함께, 부분적으로는 인간이 생성한 데이터셋에 대한 적용 가치 때문에, 우리는 또한 우리 데이터셋에 없는 것을 적극적으로 고려해야 합니다.\index{data science!ethics} 우리 데이터셋에서 체계적으로 누락된 사람은 누구입니까? 누구의 데이터가 우리가 사용하는 접근 방식에 잘 맞지 않아 부적절하게 단순화되고 있습니까? 세상이 데이터가 되는 과정에 추상화와 단순화가 필요하다면, 언제 합리적으로 단순화할 수 있고 언제 부적절한지 명확히 해야 합니다.

우리 세상이 데이터가 되는 과정에는 필연적으로 측정이 포함됩니다.\index{measurement} 역설적이게도, 측정을 하고 세부 사항에 깊이 몰두하는 사람들은 종종 그것과 동떨어진 사람들보다 데이터에 대한 신뢰가 낮습니다.\index{data!trust} 거리 측정, 경계 정의, 인구 계산과 같이 겉보기에 명확한 작업조차도 실제로는 놀랍도록 어렵습니다. 우리 세상을 데이터로 바꾸는 데는 많은 결정이 필요하고 많은 오류가 발생합니다. 다른 많은 고려 사항 중에서 무엇을 측정할 것인지, 얼마나 정확하게 측정할 것인지, 누가 측정할 것인지 결정해야 합니다.

:::{.callout-note}
## 아, 그것에 대해 좋은 데이터가 있다고 생각하시는군요!

겉보기에 간단한 것이 얼마나 빨리 어려워지는지에 대한 중요한 예는 산모 관련 사망입니다. 이는 임신 중이거나 중절 후 곧 임신 또는 그 관리와 관련된 원인으로 사망하는 여성의 수를 의미합니다[@matmortality].\index{maternal mortality} 그러한 사망의 비극을 원인별 데이터로 바꾸는 것은 어렵지만 중요합니다. 왜냐하면 그것이 미래의 사망을 완화하는 데 도움이 되기 때문입니다. 일부 국가는 모든 사망에 대한 데이터를 수집하는 잘 개발된 시민 등록 및 생명 통계(CRVS)를 가지고 있습니다.\index{civil registration and vital statistics} 그러나 많은 국가에는 CRVS가 없어 사망이 기록되지 않습니다. 사망이 기록되더라도 사망 원인을 정의하는 것은 어려울 수 있으며, 특히 자격을 갖춘 의료진이나 장비가 부족한 경우 더욱 그렇습니다. 산모 사망은 일반적으로 원인이 많기 때문에 특히 어렵습니다. 일부 CRVS 시스템에는 사망이 산모 사망으로 계산되어야 하는지 여부를 지정하기 위해 사망 등록 양식에 확인란이 있습니다[@dattanimatmortality]. 그러나 일부 선진국조차도 최근에야 이를 채택했습니다. 예를 들어, 미국에서는 2003년에야 도입되었으며,\index{United States} 2015년에도 앨라배마, 캘리포니아, 웨스트버지니아는 표준 질문을 채택하지 않았습니다[@macdorman2018failure]. 이는 산모 사망이 과소 보고되거나 잘못 분류될 위험이 있음을 의미합니다.
:::

우리는 일반적으로 세상을 데이터로 바꾸기 위해 다양한 도구를 사용합니다\index{instrumentation}. 천문학에서는\index{astronomy} 더 나은 망원경의 개발과 결국 위성 및 탐사선을 통해 다른 세계에 대한 새로운 이해가 가능해졌습니다. 마찬가지로, 우리 자신의 세상을 데이터로 바꾸는 새로운 도구가 매일 개발되고 있습니다. 한때 인구 조사가 세대를 정의하는 행사였지만, 이제는 정기적인 설문 조사, 초 단위로 제공되는 거래 데이터, 인터넷상의 거의 모든 상호 작용이 어떤 종류의 데이터가 됩니다. 이러한 도구의 개발은 흥미로운 새로운 이야기를 가능하게 했습니다.

우리 세상은 불완전하게 데이터가 됩니다.\index{data!imperfection} 그럼에도 불구하고 데이터를 사용하여 세상에 대해 배우려면 그 불완전성과 그 불완전성의 의미를 적극적으로 이해하려고 노력해야 합니다.

## 데이터 과학이란 무엇이며 세상을 배우는 데 어떻게 사용해야 할까요?

데이터 과학에 대한 합의된 정의는 없습니다.\index{data science!definition} @r4ds는 그것이 "...원시 데이터를 이해, 통찰력 및 지식으로 전환할 수 있게 해준다"고 말합니다. 마찬가지로 @leekandpeng는 그것이 "$\dots$데이터로 답할 수 있는 정량적 질문을 공식화하고, 데이터를 수집 및 정리하고, 데이터를 분석하고, 관련 청중에게 질문에 대한 답변을 전달하는 과정"이라고 주장합니다. @moderndatascience는 그것을 "$\dots$데이터에서 의미 있는 정보를 추출하는 과학"으로 간주합니다. 그리고 @timbersandfriends는 그것을 "재현 가능하고 감사 가능한 프로세스를 통해 데이터에서 통찰력을 생성하는 프로세스"로 정의합니다. 더 이전 시대의 @foster는 "(통계)는 대량의 데이터 처리 및 분석과 데이터에서 정보를 추출하는 수학적 방법 개발에 관심이 있습니다. 이 모든 활동을 컴퓨터 방법과 결합하면 부분의 합보다 더 큰 무언가를 얻게 됩니다."라고 말하며 현재 우리가 데이터 과학이라고 부르는 것을 명확하게 지적합니다.

@craiu2019hiring은 데이터 과학이 무엇인지에 대한 불확실성은 중요하지 않을 수 있다고 주장합니다. 왜냐하면 "$\dots$누가 정말로 누군가를 시인이나 과학자로 만드는지 말할 수 있겠습니까?" 그는 계속해서 데이터 과학자는 "$\dots$데이터 중심 연구 의제를 가지고 있고, 통계 방법의 원칙적인 구현을 고수하거나 열망하며 효율적인 계산 기술을 사용하는 사람"이라고 광범위하게 말합니다.

어쨌든 구체적이고 기술적인 정의와 함께 약간의 구체성을 잃더라도 간단한 정의를 갖는 것은 가치가 있습니다. 확률은 종종 비공식적으로 "사물을 세는 것"으로 정의됩니다[@citemcelreath, p. 10]. 유사한 비공식적인 의미에서 데이터 과학은 다음과 같이 정의할 수 있습니다: 인간이 사물을 측정하고, 일반적으로 다른 인간과 관련되며, 설명하고 예측하기 위해 정교한 평균을 사용하는 것.\index{data science!definition} 우리는 @sec-concluding-remarks에서 이것을 다시 방문하여 더 자세한 정의를 제공합니다.

약간 귀엽게 들릴지 모르지만, 19세기 통계학자이자 경제학자인 프랜시스 에지워스는\index{Edgeworth, Francis} 통계를 "사회 현상에 의해 제시되는 평균의 과학"으로 간주했으므로 좋은 동료를 찾은 셈입니다[@edgeworth1885methods].\index{statistics!definition} 어쨌든 이 정의의 한 가지 특징은 데이터를 *테라 눌리우스*, 즉 누구의 땅도 아닌 것으로 취급하지 않는다는 것입니다. 통계학자들은 데이터를 우리가 결코 알 수 없는 어떤 과정의 결과로 보지만, 데이터를 사용하여 이해하려고 노력합니다. 많은 통계학자들은 데이터와 측정에 깊은 관심을 가지고 있지만, 통계학에서 데이터가 그냥 나타나는 경우가 많습니다. 즉, 누구에게도 속하지 않습니다. 그러나 실제로는 그렇지 않습니다.

데이터는 생성된 다음 수집, 정리 및 준비되어야 하며 이러한 결정은 중요합니다. 모든 데이터셋은 *독자적인 종류*, 즉 그 자체로 하나의 클래스이므로 한 데이터셋을 잘 알게 되면 모든 데이터셋이 아니라 하나의 데이터셋만 알게 됩니다.

데이터 과학의 많은 부분은 "과학"에 초점을 맞추지만 "데이터"에도 초점을 맞추는 것이 중요합니다.\index{data science!importance of data} 그리고 그것이 데이터 과학에 대한 그 귀여운 정의의 또 다른 특징입니다. 일부 데이터 과학자는 광범위한 문제에 관심이 있는 제너럴리스트입니다. 종종 이러한 것들을 통합하는 것은 지저분한 데이터를 수집, 정리 및 준비해야 한다는 것입니다. 그리고 자주 가장 많은 시간이 필요하고 가장 자주 업데이트되며 가장 완전한 주의를 기울일 가치가 있는 것은 해당 데이터의 세부 사항입니다.

@Jordan2019Artificial은 진료실에 있었고, 당시 태아였던 그의 아이가 다운 증후군을 앓고 있을 확률을 산전 초기 검사를 통해 받았다고 설명합니다. 배경 지식으로, 확실히 알기 위해 검사를 할 수 있지만, 그 검사는 태아가 생존하지 못할 위험이 따르므로 이 초기 검사를 하고 부모는 일반적으로 그 초기 검사에서 나온 다운 증후군 확률을 사용하여 확정 검사를 할지 여부를 결정합니다. @Jordan2019Artificial은 초기 검사에서 제공된 확률이 10년 전에 영국에서 수행된 연구를 기반으로 결정되고 있음을 발견했습니다. 문제는 그 후 10년 동안 영상 기술이 향상되어 초기 검사에서 그렇게 고해상도 이미지를 예상하지 못했고, 그 후 초기 검사에서 다운 증후군 진단이 (거짓으로) 증가했다는 것입니다. 데이터가 문제였습니다.

:::{.callout-note}
## 거인의 어깨 위에 서서

마이클 조던 박사는\index{Jordan, Michael} 캘리포니아 대학교 버클리 캠퍼스의\index{Berkeley} 페홍 첸 특훈 교수입니다. 1985년 캘리포니아 대학교 샌디에이고 캠퍼스에서 인지 과학 박사 학위를 받은 후 MIT 조교수로 임명되었고, 1997년 정교수로 승진했으며, 1998년 버클리로 옮겼습니다. 그의 연구 분야 중 하나는 통계적 기계 학습입니다. 예를 들어, 특히 중요한 논문 중 하나는 @Blei2003latent인데, 이 논문은 텍스트를 그룹화하여 주제를 정의하는 방법을 정의했으며, @sec-text-as-data에서 이를 다룹니다.\index{text!topic models}
:::

어려운 것은 "과학" 부분만이 아니라 "데이터" 부분이기도 합니다. 예를 들어, 연구자들은 컴퓨터 과학에서 가장 인기 있는 텍스트 데이터셋 중 하나를 다시 조사했고,\index{computer science} 데이터의 약 30%가 부적절하게 중복되었다는 것을 발견했습니다[@bandy2021addressing]. 이러한 유형의 데이터셋을 전문으로 하는 전체 분야(언어학\index{linguistics})가 있으며, 부적절한 데이터 사용은 어느 한 분야가 헤게모니를 장악할 때 발생하는 위험 중 하나입니다. 데이터 과학의 강점은 다양한 배경과 훈련을 가진 사람들을 모아 어떤 데이터셋에 대해 배우는 작업에 참여시킨다는 것입니다. 과거에 수행된 작업에 제약을 받지 않습니다. 이는 우리가 우리 자신의 전통에서 오지 않았지만 우리만큼 데이터셋에 관심이 있는 사람들에게 존경심을 표하기 위해 노력해야 함을 의미합니다. 데이터 과학은 여러 분야에 걸쳐 있으며 점점 더 중요해지고 있습니다. 따라서 우리 세계를 반영해야 합니다. 데이터 과학에는 다양한 배경, 접근 방식 및 분야가 필요합니다.\index{data science!diversity}

우리 세상은 지저분하고, 우리 데이터도 마찬가지입니다. 데이터로 성공적으로 이야기를 하려면 그 과정이 어려울 것이라는 사실에 익숙해져야 합니다. 영국 수학자 해나 프라이는 문제를 해결하기 전에 코드를 다시 작성하는 데 6개월을 보냈다고 설명합니다[@hannahfryft]. 끈기 있게 노력하는 법을 배워야 합니다. 때로는 실패를 받아들여야 하며, 회복력을 키우고 내재적 동기를 가짐으로써 그렇게 합니다. 데이터의 세계는 가능성과 확률을 고려하고 그 사이에서 절충하는 법을 배우는 것입니다. 우리가 확실히 아는 것은 거의 없으며 완벽한 분석도 없습니다.

궁극적으로 우리 모두는 데이터로 이야기를 하고 있을 뿐이지만, 이러한 이야기는 점점 더 세상에서 가장 중요한 이야기가 되고 있습니다.

## 연습 문제

### 퀴즈 {.unnumbered}

1. 데이터 과학이란 무엇입니까 (자신의 말로)?
2. @register2020에 따르면 데이터 결정은 다음에 영향을 미칩니까 (하나 선택)?
    a.  실제 사람들.
    b. 아무도.
    c. 훈련 세트에 있는 사람들.
    d. 테스트 세트에 있는 사람들.
3. @keyes2019에 따르면 데이터 과학이란 무엇입니까 (하나 선택)?
    a. 데이터 과학은 과학적 방법, 프로세스, 알고리즘 및 시스템을 사용하여 많은 구조화 및 비구조화 데이터에서 지식과 통찰력을 추출하는 학제 간 분야입니다.
    b. 의사 결정을 목적으로 하는 대량 데이터의 정량적 분석.
    c.  인류를 셀 수 있는 것으로 비인간적으로 축소하는 것.
4. @keyes2019에 따르면 표준화된 범주를 요구하는 데이터 시스템의 한 가지 결과는 무엇입니까 (하나 선택)?
    a. 사용자 경험 저하.
    b. 보안 조치 손상.
    c. 기술 혁신 증가.
    d.  개인의 정체성과 경험 소멸.
5. @kieranskitchen에 따르면 데이터 작업에 대한 일반적인 비판은 무엇입니까 (하나 선택)?
    a. 너무 시간이 많이 걸리고 비효율적이라는 것.
    b.  숫자 뒤에 있는 인간 삶의 현실에서 멀어지게 한다는 것.
    c. 분석을 위해 값비싼 소프트웨어와 광범위한 교육이 필요하다는 것.
6. @kieranskitchen에 따르면 그 비판에 대한 반응은 무엇입니까 (하나 선택)?
    a.  데이터 작업은 의미에 대한 질문에 직면하도록 강요합니다.
    b. 데이터 분석은 수행되어서는 안 됩니다.
    c. 데이터는 자동화된 프로세스로만 분석되어야 합니다.
    d. 질적 접근 방식이 지배적인 접근 방식이어야 합니다.
7. @keyes2019와 @kieranskitchen을 어떻게 조화시킬 수 있습니까?
8. 윤리가 데이터 과학의 핵심 요소인 이유는 무엇입니까 (하나 선택)?
    a. 데이터 과학은 항상 민감한 개인 정보를 포함하기 때문입니다.
    b. 윤리적 고려 사항으로 인해 분석을 더 쉽게 수행할 수 있기 때문입니다.
    c.  데이터셋은 아마도 인간과 관련이 있으며 맥락을 고려해야 하기 때문입니다.
    d. 규정에 따라 모든 데이터 분석에 대해 윤리 승인이 필요하기 때문입니다.
9. 이 장에서 설명한 @crawford에 따르면 다음 중 우리 세계와 따라서 우리 데이터를 형성하는 힘은 무엇입니까 (모두 선택)?
    a.  정치적.
    b. 물리적.
    c.  역사적.
    d.  문화적.
    e.  사회적.
10. @nottomford에 따르면 컴파일러란 무엇입니까 (하나 선택)?
    a.  파일에 입력한 기호를 가져와 하위 수준 명령으로 변환하는 소프트웨어.
    b. 누군가가 입력했거나 다른 곳에서 복사하거나 붙여넣은 (일반적인 키보드 문자를 사용하여 어떤 종류의 파일에 저장된) 기호 시퀀스.
    c. 혜택이 있는 시계.
    d. 펀치 카드에 구멍을 뚫고 상자에 넣은 다음 로드하면 컴퓨터가 카드를 넘겨 구멍이 있는 위치를 식별하고 메모리 일부를 업데이트합니다.
11. 성별에 대해 질문한 설문 조사 결과를 고려하십시오. 다음과 같은 개수를 찾습니다: "남성: 879", "여성: 912", "논바이너리: 10", "응답하지 않음: 3", "기타: 1". "응답하지 않음"을 고려하는 적절한 방법은 무엇입니까 (하나 선택)?
    a. 삭제합니다.
    b.  경우에 따라 다릅니다.
    c. 포함합니다.
    d. "기타"에 병합합니다.
12. 인종 및/또는 성적 지향을 예측 변수로 포함하면 모델 성능이 향상되는 직업을 가지고 있다고 상상해 보십시오. 분석에 이러한 요소를 포함할지 여부를 결정할 때 어떤 요소를 고려하시겠습니까 (자신의 말로)?
13. 데이터 과학에서 재현성이란 무엇을 의미합니까 (하나 선택)?
    a. 다른 데이터셋으로 유사한 결과를 생성할 수 있는 것.
    b.  분석의 모든 단계를 다른 사람이 독립적으로 다시 수행할 수 있도록 보장하는 것.
    c. 동료 심사를 거친 저널에 결과를 게시하는 것.
    d. 데이터를 보호하기 위해 독점 소프트웨어를 사용하는 것.
14. 측정과 관련된 과제는 무엇입니까 (하나 선택)?
    a. 일반적으로 간단하며 거의 주의를 기울일 필요가 없습니다.
    b.  무엇을 어떻게 측정할지 결정하는 것은 복잡하고 상황에 따라 다릅니다.
    c. 데이터 수집은 객관적이며 편향이 없습니다.
    d. 측정값은 항상 정확하고 시간이 지나도 일관됩니다.
15. 조각가에 대한 비유에서 조각 행위는 데이터 워크플로에서 무엇을 나타냅니까 (하나 선택)?
    a. 데이터에 적합한 복잡한 모델 생성.
    b. 원시 데이터 획득.
    c.  필요한 데이터셋을 드러내기 위해 데이터 정리 및 준비.
    d. 결과 시각화.
16. 탐색적 데이터 분석(EDA)이 개방형 프로세스인 이유는 무엇입니까 (하나 선택)?
    a. 따라야 할 고정된 단계 집합이 있기 때문입니다.
    b.  데이터의 모양과 패턴을 이해하기 위해 지속적인 반복이 필요하기 때문입니다.
    c. 구조화된 방식으로 가설을 테스트하는 것을 포함하기 때문입니다.
    d. 자동화할 수 있기 때문입니다.
17. 통계 모델을 신중하게 사용해야 하는 이유는 무엇입니까 (하나 선택)?
    a. 항상 명확한 결과를 제공하기 때문입니다.
    b.  이전 단계에서 내린 결정을 반영할 수 있기 때문입니다.
    c. 대부분의 청중에게 너무 복잡하기 때문입니다.
    d. 데이터가 잘 제시되면 불필요하기 때문입니다.
18. 키 측정의 어려움에 대해 생각하면서 얻을 수 있는 한 가지 교훈은 무엇입니까 (하나 선택)?
    a. 키는 변동성이 거의 없는 간단한 측정값입니다.
    b. 모든 측정값은 올바른 도구로 수행하면 정확합니다.
    c.  간단한 측정값조차도 데이터 품질에 영향을 미치는 복잡성을 가질 수 있습니다.
    d. 키는 데이터 분석에서 유용한 변수가 아닙니다.
19. 데이터셋에서 누락된 사람을 고려하지 않을 경우의 위험은 무엇입니까 (하나 선택)?
    a. 분석에 큰 영향을 미치지 않습니다.
    b. 데이터 양을 줄여 분석을 단순화합니다.
    c.  전체 맥락을 나타내지 않는 결론으로 이어질 수 있습니다.
20. 통계 모델링의 목적은 무엇입니까 (하나 선택)?
    a.  데이터를 탐색하고 이해하는 데 도움이 되는 도구로서.
    b. 가설을 증명하기 위해.
    c. 탐색적 데이터 분석을 대체하기 위해.
21. "우리 데이터는 지저분하고 복잡한 세상의 단순화입니다"는 무엇을 의미합니까 (하나 선택)?
    a. 데이터는 현실의 모든 측면을 완벽하게 포착합니다.
    b.  데이터는 분석을 가능하게 하기 위해 현실을 단순화하지만 모든 세부 사항을 포착할 수는 없습니다.
    c. 데이터는 항상 부정확하고 쓸모가 없습니다.

### 수업 활동 {.unnumbered}

- 강사는 수업 사진을 찍은 다음 화면에 사진을 표시해야 합니다. 소그룹으로 학생들은 사진이 보여주는 세 가지 측면과 사진이 보여주지 않는 세 가지 측면을 식별해야 합니다. 이것이 데이터 과학과 어떻게 관련되는지 토론하십시오.
- 강사는 각 그룹에 측정에 사용할 다른 항목을 제공해야 하며, 그중 일부는 다른 항목보다 더 유용합니다(예: 줄자, 종이, 자, 마커, 저울 등). 그런 다음 학생들은 항목을 사용하여 다음 질문에 답해야 합니다. "머리카락 길이는 얼마나 됩니까?". 숫자를 스프레드시트에 추가합니다. 스프레드시트만 있다면 머리카락 길이에 대해 무엇을 이해하고 무엇을 이해하지 못하겠습니까? 이것을 데이터 과학과 더 광범위하게 관련시키십시오.

### 과제 {.unnumbered}

이 과제의 목적은 겉보기에 간단한 것조차도 측정의 어려움, 따라서 더 복잡한 영역에서 측정 문제의 가능성을 명확히 하는 것입니다.

무, 겨자잎 또는 아루굴라와 같이 빨리 자라는 식물의 씨앗을 구하십시오. 씨앗을 심고 사용한 흙의 양을 측정하십시오. 물을 주고 사용한 물의 양을 측정하십시오. 매일 변경 사항을 기록하십시오. 더 일반적으로 가능한 한 많이 측정하고 기록하십시오. 측정의 어려움에 대한 생각을 기록하십시오. 결국 씨앗이 싹트고 어떻게 자라는지 측정해야 합니다.
