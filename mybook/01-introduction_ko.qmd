---
engine: knitr
---

# 데이터로 이야기하기 {#sec-introduction}

:::{.callout-note}
채프먼 앤 홀/CRC는 이 책을 2023년 7월에 출판했습니다. [여기](https://www.routledge.com/Telling-Stories-with-Data-With-Applications-in-R/Alexander/p/book/9781032134772)에서 구매하실 수 있습니다. 이 온라인 버전은 인쇄된 내용에 일부 업데이트가 있습니다.
:::

**선행 조건**

- *셀 수 없는 것을 세기* 읽기, [@keyes2019]
  - 이 기사는 세상을 데이터로 바꾸는 것의 어려움을 논의합니다.
- *주방 카운터 천문대* 읽기, [@kieranskitchen]
  - 데이터가 무엇을 숨기고 드러내는지에 대한 논의.
- *6분 만에 데이터 과학 윤리* 시청, [@register2020]
  - 이 비디오는 윤리와 데이터 과학을 건설적인 방식으로 통합합니다.
- *코드는 무엇인가?* 읽기, [@nottomford]
  - 이 기사는 코드의 역할에 대한 개요를 제공하며, 처음 세 섹션에 집중해야 합니다.

## 이야기하기에 대하여

많은 부모들이 자녀가 태어나면 정기적으로 하는 첫 번째 일 중 하나는 자녀에게 이야기를 읽어주는 것입니다. 그렇게 함으로써 그들은 수천 년 동안 이어져 온 전통을 이어갑니다. 신화, 우화, 동화는 우리 주변 어디에서나 볼 수 있고 들을 수 있습니다. 그것들은 재미있을 뿐만 아니라 세상을 배우는 데 도움을 줍니다. 에릭 칼의 *배고픈 애벌레*가 데이터를 다루는 세상과는 거리가 멀어 보일 수 있지만, 유사점이 있습니다. 둘 다 이야기를 전달하고 지식을 전달하는 것을 목표로 합니다.

데이터를 사용할 때 우리는 설득력 있는 이야기를 전달하려고 노력합니다. 선거를 예측하는 것처럼 흥미로울 수도 있고, 인터넷 광고 클릭률을 높이는 것처럼 평범할 수도 있고, 질병의 원인을 찾는 것처럼 심각할 수도 있고, 농구 경기를 예측하는 것처럼 재미있을 수도 있습니다. 어떤 경우든 핵심 요소는 동일합니다. 20세기 초 영국 작가 E. M. 포스터는 모든 소설에 공통적인 측면을 이야기, 인물, 플롯, 환상, 예언, 패턴, 리듬으로 묘사했습니다 [@forster]. 마찬가지로, 설정에 관계없이 데이터를 사용하여 이야기를 전달할 때 공통적인 관심사가 있습니다:

1. 데이터셋은 무엇인가? 누가 왜 데이터셋을 생성했는가?
2. 데이터셋을 뒷받침하는 프로세스는 무엇인가? 그 프로세스를 고려할 때, 데이터셋에서 누락된 것이나 제대로 측정되지 않은 것은 무엇인가? 다른 데이터셋을 생성할 수 있었을까? 그렇다면 우리가 가진 데이터셋과 얼마나 다를 수 있었을까?
3. 데이터셋이 무엇을 말하려고 하며, 어떻게 그것이 말하도록 할 수 있는가? 또 무엇을 말할 수 있는가? 이들 중에서 어떻게 결정하는가?
4. 이 데이터셋에서 다른 사람들이 무엇을 보기를 바라며, 어떻게 그들을 설득할 수 있는가? 그들을 설득하기 위해 얼마나 많은 노력을 해야 하는가?
5. 이 데이터셋과 관련된 프로세스 및 결과에 누가 영향을 받는가? 데이터셋에 어느 정도 표현되어 있으며, 분석에 참여했는가?

과거에는 데이터를 사용하여 이야기를 전달하는 특정 요소가 더 쉬웠습니다. 예를 들어, 실험 설계는 농업 및 의학 과학, 물리학, 화학 분야에서 길고 견고한 전통을 가지고 있습니다. 학생의 t-분포는 1900년대 초 기네스 맥주 제조업체에서 일했던 화학자 윌리엄 실리 고셋에 의해 확인되었습니다 [@boland1984biographical]. 그가 맥주를 무작위로 샘플링하고 한 번에 한 가지 측면을 변경하는 것은 비교적 간단했을 것입니다.

오늘날 우리가 사용하는 통계 방법론의 많은 기본 원리는 그러한 환경에서 개발되었습니다. 그러한 상황에서는 일반적으로 통제 그룹을 설정하고 무작위화하는 것이 가능했으며, 윤리적 문제는 적었습니다. 결과 데이터로 전달되는 이야기는 상당히 설득력이 있었을 것입니다.

불행히도, 통계 방법론이 적용되는 다양한 환경을 고려할 때, 오늘날에는 이러한 것들이 거의 적용되지 않습니다. 반면에 우리는 많은 이점을 가지고 있습니다. 예를 들어, 잘 개발된 통계 기법, 대규모 데이터셋에 대한 더 쉬운 접근, 그리고 R 및 Python과 같은 오픈 소스 언어가 있습니다. 그러나 전통적인 실험을 수행하는 것의 어려움은 설득력 있는 이야기를 전달하기 위해 다른 측면에도 의존해야 함을 의미합니다.

## 워크플로우 구성 요소

데이터로 이야기를 전달하는 데 필요한 워크플로우에는 다섯 가지 핵심 구성 요소가 있습니다:

1. **계획**하고 최종 지점을 스케치합니다.
2. **시뮬레이션**하고 시뮬레이션된 데이터를 고려합니다.
3. 실제 데이터를 **획득**하고 준비합니다.
4. 실제 데이터를 **탐색**하고 이해합니다.
5. 수행한 작업과 발견한 내용을 **공유**합니다.

우리는 **최종 지점을 계획하고 스케치**하는 것으로 시작합니다. 이는 우리가 어디로 가고 싶은지 신중하게 생각하도록 보장하기 때문입니다. 이는 우리의 상황을 깊이 고려하도록 강제하고, 집중하고 효율적으로 유지하는 데 도움이 되며, 범위 확장을 줄이는 데 도움이 됩니다. 루이스 캐럴의 *이상한 나라의 앨리스*에서 앨리스는 체셔 고양이에게 어디로 가야 할지 묻습니다. 체셔 고양이는 앨리스가 어디로 가고 싶은지 물어봅니다. 그리고 앨리스가 어디든 상관없다고 대답하자, 체셔 고양이는 "충분히 오래 걸으면" 항상 어딘가에 도착할 것이기 때문에 방향은 중요하지 않다고 말합니다. 우리의 경우 문제는 우리가 오랫동안 목적 없이 걸을 여유가 없다는 것입니다. 최종 지점이 변경되어야 할 수도 있지만, 이것이 의도적이고 합리적인 결정이라는 것이 중요합니다. 그리고 그것은 초기 목표가 있을 때만 가능합니다. 많은 가치를 얻기 위해 너무 많은 시간을 할애할 필요는 없습니다. 종종 종이와 펜으로 10분이면 충분합니다.

다음 단계는 **데이터를 시뮬레이션**하는 것입니다. 이는 우리를 세부 사항으로 몰아넣기 때문입니다. 데이터셋의 클래스와 예상되는 값의 분포에 집중하게 하여 데이터셋을 정리하고 준비하는 데 도움이 됩니다. 예를 들어, 연령대가 정치적 선호도에 미치는 영향에 관심이 있다면, 연령대 변수가 "18-29", "30-44", "45-59", "60+"의 네 가지 가능한 값을 가진 요인일 것으로 예상할 수 있습니다. 시뮬레이션 프로세스는 실제 데이터셋이 충족해야 하는 명확한 기능을 제공합니다. 이러한 기능을 사용하여 데이터 정리 및 준비를 안내할 테스트를 정의할 수 있습니다. 예를 들어, 실제 데이터셋에서 이 네 가지 값 중 하나가 아닌 연령대를 확인할 수 있습니다. 이러한 테스트가 통과하면 연령대 변수에 예상되는 값만 포함되어 있다고 확신할 수 있습니다.

데이터 시뮬레이션은 통계 모델링으로 전환할 때도 중요합니다. 그 단계에서는 모델이 데이터셋에 있는 것을 반영하는지 여부에 관심이 있습니다. 문제는 실제 데이터셋을 바로 모델링하면 모델에 문제가 있는지 알 수 없다는 것입니다. 우리는 처음에 데이터를 시뮬레이션하여 기본 데이터 생성 프로세스를 정확히 알 수 있습니다. 그런 다음 시뮬레이션된 데이터셋에 모델을 적용합니다. 우리가 입력한 것을 얻으면 모델이 적절하게 작동하고 있음을 알 수 있으며, 실제 데이터셋으로 전환할 수 있습니다. 시뮬레이션된 데이터에 대한 초기 적용 없이는 모델에 대한 확신을 갖기가 더 어려울 것입니다.

시뮬레이션은 종종 저렴합니다. 현대 컴퓨팅 자원과 프로그래밍 언어를 고려할 때 거의 무료입니다. 그리고 빠릅니다.\index{simulation} 이는 "상황에 대한 친밀한 느낌"을 제공합니다 [@hamming1996, p. 239]. 필수적인 것만 포함하는 시뮬레이션으로 시작하여 작동하게 한 다음 복잡하게 만드십시오.

우리가 관심 있는 **데이터를 획득하고 준비**하는 것은 종종 간과되는 워크플로우 단계입니다. 이는 가장 어려운 단계 중 하나일 수 있고 많은 결정을 내려야 하기 때문에 놀라운 일입니다. 이는 점점 더 연구의 대상이 되고 있으며, 이 단계에서 내려진 결정이 통계 결과에 영향을 미칠 수 있음이 밝혀졌습니다 [@huntington2021influence; @AhadyDolatsara2021; @Gould2023].

이 워크플로우 단계에서는 약간 압도당하는 느낌을 받는 것이 일반적입니다. 일반적으로 우리가 얻을 수 있는 데이터는 우리를 약간 두렵게 만듭니다. 데이터가 너무 적을 수도 있고, 이 경우 통계 기계를 어떻게 작동시킬지 걱정할 수 있습니다. 또는 그 반대 문제에 직면하여 그렇게 많은 양의 데이터를 어떻게 처리하기 시작할지 걱정할 수도 있습니다.

> 아마도 우리 삶의 모든 용들은 공주님일 것입니다. 단 한 번이라도 아름다움과 용기로 행동하는 것을 기다리고 있는. 아마도 우리를 두렵게 하는 모든 것은 가장 깊은 본질에서 우리의 사랑을 원하는 무력한 것일 것입니다.
>
> @rilke

이 워크플로우 단계에서 편안함을 느끼는 것은 나머지 단계를 해제합니다. 설득력 있는 이야기를 전달하는 데 필요한 데이터셋이 그 안에 있습니다. 그러나 조각가처럼, 우리는 필요 없는 모든 데이터를 반복적으로 제거하고, 필요한 데이터를 형성해야 합니다.

데이터셋을 얻은 후에는 해당 데이터셋의 특정 관계를 **탐색하고 이해**하고 싶을 것입니다. 우리는 일반적으로 기술 통계로 프로세스를 시작한 다음 통계 모델로 이동합니다. 데이터의 함의를 이해하기 위해 통계 모델을 사용하는 것은 편향에서 자유롭지 않으며, "진실"도 아닙니다. 모델은 우리가 지시하는 대로 작동합니다.\index{model!role} 데이터를 사용하여 이야기를 전달할 때, 통계 모델은 그래프와 표를 사용하는 것과 마찬가지로 데이터셋을 탐색하는 데 사용하는 도구 및 접근 방식입니다. 그것들은 우리에게 결정적인 결과를 제공하지는 않지만, 특정 방식으로 데이터셋을 더 명확하게 이해할 수 있도록 해줄 것입니다.

워크플로우의 이 단계에 도달할 때쯤에는 모델은 어떤 종류의 기본 데이터 생성 프로세스를 반영하는 것만큼이나 초기 단계, 특히 획득 및 정리에서 내려진 결정을 반영할 것입니다. 정교한 모델러는 자신의 통계 모델이 수면 위의 빙산 조각과 같다는 것을 알고 있습니다. 즉, 데이터라는 아래의 대부분 덕분에 구축되고 가능합니다. 그러나 전체 데이터 과학 워크플로우의 전문가는 모델링을 사용할 때 얻은 결과가 누구의 데이터가 중요한지, 데이터를 측정하고 기록하는 방법에 대한 결정, 그리고 데이터가 특정 워크플로우에서 사용 가능하기 훨씬 전에 세상을 반영하는 다른 측면과 같은 선택으로 인해 추가적으로 발생한다는 것을 인식합니다.\index{data science!workflow}

마지막으로, 우리가 수행한 작업과 발견한 내용을 가능한 한 높은 충실도로 **공유**해야 합니다. 자신만이 가지고 있는 지식에 대해 이야기하는 것은 여러분을 지식인으로 만들지 않으며, 여기에는 "과거의 당신"만이 가지고 있는 지식도 포함됩니다. 소통할 때, 우리가 내린 결정, 그 결정을 내린 이유, 우리의 발견, 그리고 우리 접근 방식의 약점에 대해 명확하게 설명해야 합니다. 우리는 중요한 것을 밝혀내려고 노력하고 있으므로, 처음에는 모든 것을 기록해야 하지만, 이 서면 커뮤니케이션은 나중에 다른 형태의 커뮤니케이션으로 보완될 수 있습니다. 이 워크플로우에서 내려야 할 결정이 너무 많기 때문에 우리는 전체 과정에 대해 개방적이어야 합니다. 통계 모델링과 그래프 및 표 생성뿐만 아니라 모든 것입니다. 이것이 없으면 데이터에 기반한 이야기는 신뢰성을 잃습니다.

세상은 모든 것이 신중하고 현명하게 평가되는 합리적인 능력주의가 아닙니다. 대신, 우리는 경험을 바탕으로 지름길, 해킹, 휴리스틱을 사용합니다. 불분명한 의사소통은 아무리 훌륭한 작업이라도 제대로 이해되지 못하게 하여 무의미하게 만들 것입니다. 의사소통에는 최소한의 기준이 있지만, 얼마나 인상적일 수 있는지에 대한 상한선은 없습니다. 잘 생각된 워크플로우의 정점일 때, 심지어 일종의 *스프레차투라* 또는 의도적인 무심함을 얻을 수도 있습니다. 이러한 숙달을 달성하려면 수년간의 노력이 필요합니다.

## 데이터로 이야기하기

데이터에 기반한 설득력 있는 이야기는 대략 10~20페이지 정도로 전달될 수 있습니다. 이보다 적으면 세부 사항이 너무 부족할 가능성이 있습니다. 그리고 훨씬 더 많이 작성하는 것은 쉽지만, 종종 약간의 성찰을 통해 간결성을 높이거나 여러 이야기를 분리할 수 있습니다.

전통적인 실험을 수행할 수 없는 경우에도 설득력 있는 이야기를 전달할 수 있습니다. 이러한 접근 방식은 "빅 데이터"에 의존하지 않고 (이는 만병통치약이 아닙니다 [@meng2018statistical; @Bradley2021]), 대신 사용 가능한 데이터를 더 잘 활용하는 데 중점을 둡니다. 연구 및 독립 학습, 이론과 응용의 혼합, 이 모든 것이 실용적인 기술, 정교한 워크플로우, 그리고 자신이 모르는 것에 대한 이해와 결합되면 종종 지속적인 지식을 창출하기에 충분합니다.

데이터에 기반한 최고의 이야기는 다학제적인 경향이 있습니다. 필요한 분야에서 무엇이든 가져오지만, 거의 항상 통계,\index{statistics} 소프트웨어 공학,\index{software engineering} 경제학,\index{economics} 그리고 공학\index{engineering} (몇 가지만 언급하자면)을 활용합니다. 따라서 엔드투엔드 워크플로우는 이러한 분야의 기술을 혼합해야 합니다. 이러한 기술을 배우는 가장 좋은 방법은 실제 데이터를 사용하여 다음과 같은 연구 프로젝트를 수행하는 것입니다:

- 연구 질문 개발;
- 관련 데이터셋 획득 및 정리;
- 해당 질문에 답하기 위해 데이터 탐색; 그리고
- 의미 있는 방식으로 소통.

데이터로 설득력 있는 이야기를 전달하는 핵심 요소는 다음과 같습니다:

1. 커뮤니케이션.
2. 재현성.
3. 윤리.
4. 질문.
5. 측정.
6. 데이터 수집.
7. 데이터 정리.
8. 탐색적 데이터 분석.
9. 모델링.
10. 스케일링.

이러한 요소는 좋은 연구 수행(윤리 및 질문), 신뢰할 수 있는 답변 도출(측정, 수집, 정리, 탐색적 데이터 분석 및 모델링), 그리고 설득력 있는 설명 생성(커뮤니케이션, 재현성 및 스케일링)을 포함한 몇 가지 다른 범주로 고려될 수 있습니다. 이러한 요소는 워크플로우가 구축되는 기반입니다(@fig-iceberg).

![워크플로우는 다양한 요소를 기반으로 구축됩니다](figures/iceberg.png){#fig-iceberg width=70% fig-align="center"}

이것은 마스터하기에 많은 것이지만, **커뮤니케이션**이 가장 중요합니다. 간단한 분석을 잘 전달하는 것이 복잡한 분석을 제대로 전달하지 못하는 것보다 더 가치 있습니다. 후자는 다른 사람들이 이해하거나 신뢰할 수 없기 때문입니다. 명확한 의사소통의 부족은 때때로 연구자가 무엇이 진행되고 있는지, 또는 심지어 무엇을 하고 있는지 이해하지 못하는 실패를 반영합니다. 따라서 분석 수준은 데이터셋, 도구, 작업 및 기술 세트에 맞춰야 하지만, 명확성과 복잡성 사이에서 절충이 필요할 때에는 명확성을 우선하는 것이 합리적일 수 있습니다.

명확한 커뮤니케이션은 표, 그래프, 모델의 도움을 받아 평이한 언어로 작성하여 청중을 함께 이끌어가는 것을 의미합니다. 이는 무엇을 했고 왜 했는지, 그리고 무엇을 발견했는지 명확히 설명하는 것을 의미합니다. 최소한의 기준은 다른 사람이 여러분이 한 일을 독립적으로 다시 수행하고 여러분이 발견한 것을 찾을 수 있을 정도로 수행하는 것입니다. 한 가지 과제는 데이터에 몰입할수록 처음 접했을 때 어땠는지 기억하기 어렵다는 것입니다. 그러나 대부분의 청중은 그 지점에서 시작할 것입니다. 적절한 수준의 뉘앙스와 세부 사항을 제공하는 방법을 배우는 것은 어려울 수 있지만, 청중의 이익을 위해 글을 쓰는 데 집중하면 더 쉬워집니다.

**재현성**은 세상에 대한 지속적인 지식을 창출하는 데 필요합니다. 이는 수행된 모든 작업, 즉 처음부터 끝까지 모든 작업이 독립적으로 다시 수행될 수 있음을 의미합니다. 이상적으로는 자율적인 엔드투엔드 재현성이 가능합니다. 즉, 누구나 코드, 데이터 및 환경을 얻어 수행된 모든 것을 확인할 수 있습니다 [@heil2021reproducibility]. 코드에 대한 무제한 접근은 거의 항상 가능합니다. 데이터에 대한 기본 기대치도 마찬가지이지만, 항상 합리적인 것은 아닙니다. 예를 들어, 심리학 연구는 개인 식별이 가능한 작은 샘플을 가질 수 있습니다. 한 가지 방법은 유사한 속성을 가진 시뮬레이션된 데이터를 공개적으로 공유하고, 적절한 *bona fides*가 주어지면 실제 데이터에 액세스할 수 있는 프로세스를 정의하는 것입니다. 통계 모델은 일반적으로 광범위한 수동 검사를 받습니다. 재현성의 또 다른 측면은 광범위한 자동화된 테스트를 유사하게 포함해야 한다는 것입니다.

데이터셋이 인간과 관련될 가능성이 높기 때문에 **윤리**에 대한 적극적인 고려가 필요합니다. 이는 데이터셋에 누가 포함되어 있는지, 누가 누락되었는지, 그리고 그 이유는 무엇인지와 같은 사항을 고려하는 것을 의미합니다.\index{ethics!missing data}\index{data!ethics of missing data} 우리의 이야기가 과거를 어느 정도 영속시킬 것인가? 그리고 이것이 일어나야 할 일인가? 데이터셋이 인간과 관련되지 않더라도, 이야기는 인간에 의해 구성될 가능성이 높으며, 우리는 거의 모든 다른 것에 영향을 미칩니다. 이는 우리가 환경 영향과 불평등에 대한 우려를 가지고 데이터를 윤리적으로 사용해야 할 책임이 있음을 의미합니다.

윤리에 대한 많은 정의가 있지만, 데이터를 사용하여 이야기를 전달하는 데 있어서 최소한 데이터셋의 전체 맥락을 고려하는 것을 의미합니다 [@datafeminism2020]. 법학에서 법에 대한 텍스트적 접근 방식은 인쇄된 법의 단어를 문자 그대로 고려하는 것을 의미하는 반면, 목적론적 접근 방식은 법이 더 넓은 맥락에서 해석되는 것을 의미합니다. 데이터를 사용하여 이야기를 전달하는 윤리적 접근 방식은 후자의 접근 방식을 채택하고, 우리 세상과 따라서 우리의 데이터를 형성하는 사회적, 문화적, 역사적, 정치적 힘을 고려하는 것을 의미합니다 [@crawford].\index{data science!ethics}

호기심은 데이터셋과 관련 프로세스를 적절한 범위까지 탐색하려는 내적 동기를 제공합니다. **질문**은 질문을 낳는 경향이 있으며, 데이터셋을 이해하는 과정이 계속됨에 따라 일반적으로 개선되고 정교해집니다. 종종 가르치는 가설 검정의 포퍼주의적 접근 방식과는 대조적으로, 질문은 일반적으로 지속적이고 진화하는 프로세스를 통해 개발됩니다 [@franklin2005exploratory]. 초기 질문을 찾는 것은 어려울 수 있습니다. 연구 질문을 합리적으로 사용 가능한 측정 가능한 변수로 조작하는 것은 특히 어렵습니다. 관심 분야를 선택하는 것이 도움이 될 수 있으며, 광범위한 주장을 스케치하여 특정 질문으로 발전시키고, 마지막으로 두 가지 다른 영역을 결합하는 것도 도움이 될 수 있습니다.

실제 데이터의 혼란스러움에 익숙해지고 편안함을 느끼는 것은 데이터가 업데이트될 때마다 새로운 질문을 할 수 있다는 것을 의미합니다. 그리고 데이터셋을 자세히 아는 것은 예상치 못한 그룹화 또는 값을 표면화하는 경향이 있으며, 이를 주제 영역 전문가와 협력하여 이해할 수 있습니다. 다양한 영역에 걸쳐 지식 기반을 개발하여 일종의 "하이브리드"가 되는 것은 특히 가치 있으며, 처음에는 어리석은 질문을 할 가능성에 익숙해지는 것도 마찬가지입니다.

**측정**과 **데이터 수집**은 우리 세상이 어떻게 데이터가 될 것인지를 결정하는 것입니다. 그것들은 어렵습니다.\index{measurement}\index{data!collection} 세상은 너무나 활기차서 일관되게 측정하고 수집할 수 있는 것으로 축소하기 어렵습니다. 예를 들어, 누군가의 키를 생각해 봅시다. 우리는 아마도 키를 측정하기 전에 신발을 벗어야 한다는 데 동의할 것입니다. 그러나 우리의 키는 하루 종일 변합니다. 그리고 줄자로 키를 측정하는 것은 레이저를 사용하는 것과는 다른 결과를 줄 것입니다. 따라서 사람 간 또는 시간 경과에 따른 키를 비교하는 경우, 매일 같은 시간에 같은 방법으로 측정하는 것이 중요합니다. 그러나 이는 빠르게 불가능해집니다. 그리고 이는 이러한 데이터의 데이터베이스 표현과 관련된 문제를 제쳐두는 것입니다 [@kentheight].

우리가 관심 있는 대부분의 질문은 키보다 더 복잡한 데이터를 사용할 것입니다. 누군가가 얼마나 슬픈지 어떻게 측정합니까? 고통을 어떻게 측정합니까? 무엇을 측정하고 어떻게 측정할지 누가 결정합니까? 세상을 값으로 축소하고 이를 비교할 수 있다고 생각하는 데는 일정한 오만이 필요합니다. 궁극적으로 우리는 그렇게 해야 하지만, 측정할 대상을 일관되게 정의하는 것은 어렵습니다. 이 과정은 가치 중립적이지 않습니다. 이 잔인한 축소를 합리적으로 받아들이는 유일한 방법은 우리가 측정하고 수집하는 것을 깊이 이해하고 존중하는 것입니다. 핵심 본질은 무엇이며, 무엇을 제거할 수 있습니까?

20세기 스페인 화가 파블로 피카소는 한 줄만 사용하여 동물의 윤곽을 묘사한 일련의 그림을 그렸습니다(@fig-lumpthedog). 단순함에도 불구하고 우리는 어떤 동물이 묘사되고 있는지 알아봅니다. 그림은 동물이 고양이 아닌 개임을 알려주기에 충분합니다. 이것을 사용하여 개가 아픈지 여부를 판단할 수 있을까요? 아마 아닐 것입니다. 우리는 다른 묘사를 원할 것입니다. 무엇을 측정해야 하는지, 그리고 우리가 고려하기로 결정한 것들 중에서 어떤 특징을 측정하고 수집해야 하는지, 그리고 어떤 것을 무시해야 하는지에 대한 결정은 맥락과 목적에 따라 달라집니다.

![파블로 피카소의 이 그림은 한 줄로만 그려졌음에도 불구하고 분명히 개입니다](figures/lump.png){#fig-lumpthedog width=70% fig-align="center"}

**데이터 정리 및 준비**는 데이터를 사용하는 데 중요한 부분입니다.\index{data!cleaning} 우리는 사용할 수 있는 데이터를 사용할 수 있는 데이터셋으로 정리해야 합니다. 이는 많은 결정을 내려야 합니다. 데이터 정리 및 준비 단계는 중요하며, 다른 어떤 단계만큼이나 많은 관심과 주의를 기울여야 합니다.

@kennedy2020using 을 따라 잠재적으로 민감한 주제인 성별에 대한 정보를 수집한 설문조사를 고려해 봅시다. 네 가지 옵션: "남성", "여성", "말하고 싶지 않음", 그리고 "기타"를 사용했으며, "기타"는 열린 텍스트 상자로 해제되었습니다.\index{gender!surveys} 이 데이터셋을 접하면 대부분의 응답이 "남성" 또는 "여성"임을 알 수 있을 것입니다. "말하고 싶지 않음"에 대해 어떻게 해야 할지 결정해야 합니다. 데이터셋에서 이를 삭제하면 이 응답자들을 적극적으로 무시하는 것입니다. 삭제하지 않으면 분석이 더 복잡해집니다. 마찬가지로, 열린 텍스트 응답을 어떻게 처리할지 결정해야 합니다. 다시 말하지만, 이러한 응답을 삭제할 수 있지만, 이는 일부 응답자의 경험을 무시하는 것입니다. 또 다른 옵션은 이를 "말하고 싶지 않음"과 병합하는 것이지만, 이는 응답자들이 해당 옵션을 명시적으로 선택하지 않았기 때문에 응답자들을 무시하는 것입니다.

많은 데이터 정리 및 준비 상황에서 쉽거나 항상 올바른 선택은 없습니다. 이는 맥락과 목적에 따라 달라집니다. 데이터 정리 및 준비에는 이와 같은 많은 선택이 포함되며, 다른 사람들이 무엇을 했고 왜 했는지 이해할 수 있도록 모든 단계를 기록하는 것이 중요합니다. 데이터는 결코 스스로 말하지 않습니다. 데이터는 데이터를 정리하고 준비한 복화술사의 꼭두각시입니다.

데이터셋의 모양과 느낌을 이해하는 과정은 **탐색적 데이터 분석**(EDA)이라고 합니다.\index{exploratory data analysis} 이것은 개방형 프로세스입니다. 공식적으로 모델링하기 전에 데이터셋의 형태를 이해해야 합니다. EDA 프로세스는 요약 통계, 그래프, 표, 때로는 모델링을 생성하는 반복적인 프로세스입니다. 공식적으로 끝나지 않는 프로세스이며 다양한 기술을 필요로 합니다.

EDA가 끝나고 공식적인 통계 모델링이 시작되는 지점을 명확히 구분하기는 어렵습니다. 특히 신념과 이해가 어떻게 발전하는지 고려할 때 더욱 그렇습니다 [@Hullman2021Designing]. 그러나 핵심적으로는 데이터에서 시작하며, 데이터에 몰입하는 것을 포함합니다 [@Cook2021Foundation]. EDA는 일반적으로 최종 스토리에 명시적으로 포함되지 않습니다. 그러나 우리가 전달하는 스토리를 이해하는 데 중심적인 역할을 합니다. EDA 중에 취한 모든 단계를 기록하고 공유하는 것이 중요합니다.

**통계 모델링**은 길고 견고한 역사를 가지고 있습니다.\index{model!building} 통계에 대한 우리의 지식은 수백 년에 걸쳐 구축되었습니다.\index{statistics} 통계는 일련의 건조한 정리와 증명이 아니라 세상을 탐색하는 방법입니다. 이는 "외국어 또는 대수학 지식과 유사합니다. 언제 어떤 상황에서도 유용할 수 있습니다" [@bowley, p. 4]. 통계 모델은 "이것이라면 저것"과 같은 방식으로 순진하게 따라야 할 레시피가 아니라 데이터를 이해하는 방법입니다 [@islr]. 모델링은 일반적으로 데이터에서 통계적 패턴을 추론하는 데 필요합니다. 더 공식적으로, 통계적 추론은 "데이터를 사용하여 데이터를 생성한 분포를 추론하는 과정"입니다 [@wasserman p. 87].

통계적 유의성은 과학적 유의성과 동일하지 않으며, 우리는 지배적인 패러다임의 대가를 깨닫고 있습니다. 데이터에 대한 임의의 합격/불합격 통계 테스트를 사용하는 것은 거의 적절하지 않습니다. 대신, 통계 모델링의 적절한 사용은 일종의 반향 위치 측정과 같습니다. 우리는 모델에서 우리에게 돌아오는 것을 듣고 세상의 형태에 대해 배우는 데 도움을 받으면서, 그것이 세상의 한 가지 표현일 뿐임을 인식합니다.

R 및 Python과 같은 프로그래밍 언어의 사용은 작업을 빠르게 **확장**할 수 있도록 합니다.\index{R}\index{Python} 이는 입력과 출력 모두를 의미합니다. 10개의 관측치를 고려하는 것이 1,000개, 심지어 1,000,000개를 고려하는 것만큼이나 쉽습니다. 이를 통해 우리의 이야기가 어느 정도 적용되는지 더 빨리 확인할 수 있습니다. 또한 우리의 출력을 한 사람이 소비하는 것만큼이나 10명, 또는 100명이 쉽게 소비할 수 있습니다. API(응용 프로그래밍 인터페이스)를 사용하면 우리의 이야기가 초당 수천 번 고려될 수도 있습니다.

## 우리 세상은 어떻게 데이터가 되는가?

> 에딩턴의 유명한 이야기가 있습니다. 어떤 사람들이 그물로 바다에서 물고기를 잡았습니다. 잡은 물고기의 크기를 조사한 후, 그들은 바다에 있는 물고기의 최소 크기가 있다고 결정했습니다! 그들의 결론은 사용된 도구에서 비롯된 것이지 현실에서 비롯된 것이 아닙니다.
>
> @hamming1996 [p. 177]

어느 정도 우리는 시간을 낭비하고 있습니다. 우리는 세상의 완벽한 모델을 가지고 있습니다. 그것은 세상입니다! 그러나 너무 복잡합니다. 모든 것이 그것에 영향을 미치는 셀 수 없는 요인에 의해 완벽하게 영향을 받는다는 것을 완벽하게 안다면, 우리는 동전 던지기, 주사위 굴리기, 그리고 다른 모든 무작위 과정들을 매번 완벽하게 예측할 수 있을 것입니다. 그러나 우리는 할 수 없습니다. 대신, 우리는 합리적으로 측정 가능한 것으로 단순화해야 하며, 그것이 우리가 데이터라고 정의하는 것입니다. 우리의 데이터는 파생된 지저분하고 복잡한 세상의 단순화입니다.

"합리적으로 측정 가능"에 대한 다양한 근사치가 있습니다. 따라서 데이터셋은 항상 선택의 결과입니다.\index{data!as the result of choices} 우리는 현재 작업에 대해 여전히 합리적인지 여부를 결정해야 합니다. 우리는 통계 모델을 사용하여 데이터를 깊이 생각하고, 탐색하고, 더 잘 이해하는 데 도움을 받습니다.

많은 통계학은 우리가 가진 데이터를 철저히 고려하는 데 중점을 둡니다.\index{statistics} 이는 우리의 데이터가 농업, 천문학 또는 물리 과학에서 비롯되었을 때 적절했습니다. 이것은 비인간적 맥락에서 체계적인 편향이 존재하거나 영향을 미칠 수 없다는 것을 의미하는 것이 아니라, 데이터 과학의 부상과 함께, 부분적으로는 인간이 생성한 데이터셋에 대한 적용 가치 때문에, 우리는 데이터셋에 없는 것을 적극적으로 고려해야 합니다.\index{data science!ethics} 우리 데이터셋에서 체계적으로 누락된 사람은 누구입니까? 우리 접근 방식에 잘 맞지 않아 부적절하게 단순화되는 데이터는 누구의 데이터입니까? 세상이 데이터가 되는 과정이 추상화와 단순화를 필요로 한다면, 우리는 언제 합리적으로 단순화할 수 있고 언제 부적절할지 명확히 해야 합니다.

우리 세상이 데이터가 되는 과정은 필연적으로 측정을 포함합니다.\index{measurement} 역설적으로, 종종 측정을 수행하고 세부 사항에 깊이 몰입하는 사람들은 그것에서 벗어난 사람들보다 데이터에 대한 신뢰가 적습니다.\index{data!trust} 거리 측정, 경계 정의, 인구 계산과 같은 겉보기에 명확한 작업조차도 실제로는 놀랍도록 어렵습니다. 우리 세상을 데이터로 바꾸는 것은 많은 결정을 필요로 하고 많은 오류를 발생시킵니다. 다른 많은 고려 사항 중에서, 우리는 무엇을 측정할지, 얼마나 정확하게 측정할지, 그리고 누가 측정을 수행할지 결정해야 합니다.

:::{.callout-note}
## 오, 우리가 그 데이터에 대해 좋은 데이터를 가지고 있다고 생각하는군요!

겉보기에 간단해 보이는 것이 빠르게 어려워지는 중요한 예시는 산모 관련 사망입니다. 이는 임신 중이거나 낙태 직후, 임신 또는 그 관리와 관련된 원인으로 사망하는 여성의 수를 의미합니다 [@matmortality].\index{maternal mortality} 이러한 사망의 비극을 원인별 데이터로 바꾸는 것은 어렵지만 중요합니다. 이는 미래의 사망을 완화하는 데 도움이 되기 때문입니다. 일부 국가에는 모든 사망에 대한 데이터를 수집하는 잘 개발된 민사 등록 및 생체 통계(CRVS) 시스템이 있습니다.\index{civil registration and vital statistics} 그러나 많은 국가에는 CRVS가 없어 기록되지 않은 사망이 발생합니다. 사망이 기록되더라도, 특히 자격을 갖춘 의료 인력이나 장비가 부족할 때 사망 원인을 정의하는 것이 어려울 수 있습니다. 산모 사망은 일반적으로 많은 원인이 있기 때문에 특히 어렵습니다. 일부 CRVS 시스템에는 사망 등록 양식에 사망을 산모 사망으로 간주해야 하는지 여부를 지정하는 확인란이 있습니다 [@dattanimatmortality]. 그러나 일부 선진국조차도 최근에야 이를 채택했습니다. 예를 들어, 미국\index{United States}에서는 2003년에야 도입되었으며, 2015년에도 앨라배마, 캘리포니아, 웨스트버지니아는 표준 질문을 채택하지 않았습니다 [@macdorman2018failure]. 이는 산모 사망이 과소 보고되거나 잘못 분류될 위험이 있음을 의미합니다.
:::

우리는 일반적으로 다양한 도구\index{instrumentation}를 사용하여 세상을 데이터로 바꿉니다. 천문학에서\index{astronomy} 더 나은 망원경, 그리고 결국 위성과 탐사선의 개발은 다른 세계에 대한 새로운 이해를 가능하게 했습니다. 마찬가지로, 우리 자신의 세상을 데이터로 바꾸는 새로운 도구들이 매일 개발되고 있습니다. 한때 인구 조사가 세대를 정의하는 사건이었지만, 이제는 정기적인 설문조사, 초 단위로 사용 가능한 거래 데이터, 그리고 인터넷의 거의 모든 상호 작용이 어떤 종류의 데이터가 됩니다. 이러한 도구의 개발은 흥미로운 새로운 이야기를 가능하게 했습니다.

우리 세상은 불완전하게 데이터가 됩니다.\index{data!imperfection} 그럼에도 불구하고 데이터를 사용하여 세상을 배우려면, 우리는 데이터의 불완전성과 그 불완전성의 함의를 적극적으로 이해하려고 노력해야 합니다.

## 데이터 과학이란 무엇이며, 세상을 배우기 위해 어떻게 사용해야 하는가?

데이터 과학에 대한 합의된 정의는 없습니다.\index{data science!definition} @r4ds 는 "...원시 데이터를 이해, 통찰력, 지식으로 바꿀 수 있도록 합니다."라고 말합니다. 마찬가지로, @leekandpeng 은 "...데이터로 답할 수 있는 양적 질문을 공식화하고, 데이터를 수집하고 정리하고, 데이터를 분석하고, 질문에 대한 답을 관련 청중에게 전달하는 과정"이라고 주장합니다. @moderndatascience 는 이를 "...데이터에서 의미 있는 정보를 추출하는 과학"으로 간주합니다. 그리고 @timbersandfriends 는 이를 "재현 가능하고 감사 가능한 프로세스를 통해 데이터에서 통찰력을 생성하는 과정"으로 정의합니다. 더 이전 시대에 @foster 는 우리가 지금 데이터 과학이라고 부르는 것을 명확하게 지적합니다. 그는 "(통계는) 방대한 데이터를 처리하고 분석하며, 데이터에서 정보를 추출하는 수학적 방법을 개발하는 것과 관련이 있습니다. 이 모든 활동을 컴퓨터 방법과 결합하면 각 부분의 합보다 더 큰 것을 얻을 수 있습니다."라고 말합니다.

@craiu2019hiring 는 데이터 과학이 무엇인지에 대한 불확실성이 중요하지 않을 수 있다고 주장합니다. 왜냐하면 "...누가 시인이나 과학자를 만드는지 정말로 말할 수 있겠습니까?" 그는 데이터 과학자를 "...데이터 기반 연구 의제를 가지고 있고, 통계 방법의 원칙적인 구현을 준수하거나 열망하며, 효율적인 계산 기술을 사용하는 사람"이라고 광범위하게 말합니다.

어떤 경우든, 구체적인 기술적 정의와 함께, 약간의 특수성을 잃더라도 간단한 정의를 갖는 것이 가치가 있습니다. 확률은 종종 비공식적으로 "사물을 세는 것"으로 정의됩니다 [@citemcelreath, p. 10]. 유사한 비공식적 의미에서 데이터 과학은 다음과 같이 정의될 수 있습니다: 인간이 사물을 측정하고, 일반적으로 다른 인간과 관련되며, 정교한 평균을 사용하여 설명하고 예측하는 것.\index{data science!definition} 우리는 더 자세한 정의를 제공하기 위해 @sec-concluding-remarks에서 이를 다시 다룹니다.

그것은 약간 귀엽게 들릴 수 있지만, 19세기 통계학자이자 경제학자인 프랜시스 에지워스\index{Edgeworth, Francis}는 통계를 "사회 현상에 의해 제시되는 수단"의 과학으로 간주했으므로 좋은 동반자를 찾았습니다 [@edgeworth1885methods].\index{statistics!definition} 어떤 경우든, 이 정의의 한 가지 특징은 데이터를 *테라 눌리우스* 또는 무주지로 취급하지 않는다는 것입니다. 통계학자들은 데이터를 우리가 결코 알 수 없는 어떤 과정의 결과로 보지만, 데이터를 사용하여 이해하려고 노력합니다. 많은 통계학자들은 데이터와 측정에 깊이 관심을 기울이지만, 통계학에는 데이터가 그냥 나타나는 많은 경우가 있습니다. 데이터는 누구의 소유도 아닙니다. 그러나 실제로는 결코 그렇지 않습니다.

데이터는 생성되고, 수집되고, 정리되고, 준비되어야 하며, 이러한 결정은 중요합니다. 모든 데이터셋은 *sui generis*, 즉 그 자체로 하나의 클래스이므로, 하나의 데이터셋을 잘 알게 되면 모든 데이터셋이 아닌 하나의 데이터셋만 알게 됩니다.

많은 데이터 과학은 "과학"에 초점을 맞추지만, "데이터"에도 초점을 맞추는 것이 중요합니다.\index{data science!importance of data} 그리고 그것이 데이터 과학의 귀여운 정의의 또 다른 특징입니다. 일부 데이터 과학자는 광범위한 문제에 관심이 있는 제너럴리스트입니다. 종종 이들을 하나로 묶는 것은 지저분한 데이터를 수집하고 정리하고 준비해야 하는 필요성입니다. 그리고 종종 가장 많은 시간을 필요로 하고, 가장 자주 업데이트되며, 가장 많은 관심을 기울일 가치가 있는 것은 바로 그 데이터의 세부 사항입니다.

@Jordan2019Artificial 은 의료 사무실에서 산전 초기 검사를 기반으로 자신의 자녀(당시 태아)가 다운 증후군을 앓을 확률을 받았다고 설명합니다. 배경 설명을 하자면, 확실히 알기 위한 검사를 할 수 있지만, 그 검사는 태아가 생존하지 못할 위험이 있으므로, 이 초기 검사를 수행한 다음 부모는 일반적으로 초기 검사에서 얻은 다운 증후군 확률을 사용하여 결정적인 검사를 할지 여부를 결정합니다. @Jordan2019Artificial 은 초기 검사에서 제공된 확률이 10년 전에 영국에서 수행된 연구를 기반으로 결정되고 있음을 발견했습니다. 문제는 그 후 10년 동안 영상 기술이 향상되어 초기 검사가 그렇게 고해상도 이미지를 예상하지 못했고, 초기 검사에서 다운 증후군 진단이 (잘못된) 증가가 있었다는 것입니다. 데이터가 문제였습니다.

:::{.callout-note}
## 거인의 어깨

마이클 조던 박사\index{Jordan, Michael}는 캘리포니아 대학교 버클리\index{Berkeley}의 페홍 첸 석좌 교수입니다. 1985년 캘리포니아 대학교 샌디에이고에서 인지 과학 박사 학위를 취득한 후, MIT 조교수로 임용되었고 1997년 정교수로 승진했으며, 1998년 버클리로 옮겼습니다. 그의 연구 분야 중 하나는 통계적 머신러닝입니다. 예를 들어, 특히 중요한 논문 중 하나는 @Blei2003latent 이며, 이는 텍스트를 그룹화하여 주제를 정의하는 방법을 정의했으며, 우리는 @sec-text-as-data 에서 이를 다룹니다.\index{text!topic models}
:::

어려운 것은 "과학" 부분만이 아니라 "데이터" 부분도 마찬가지입니다. 예를 들어, 연구원들은 컴퓨터 과학에서 가장 인기 있는 텍스트 데이터셋 중 하나를 다시 조사했고,\index{computer science} 데이터의 약 30%가 부적절하게 중복되었음을 발견했습니다 [@bandy2021addressing]. 이러한 유형의 데이터셋을 전문으로 하는 전체 분야인 언어학\index{linguistics}이 있으며, 데이터의 부적절한 사용은 어떤 분야가 헤게모니를 가질 때의 위험 중 하나입니다. 데이터 과학의 강점은 다양한 배경과 훈련을 가진 사람들을 데이터셋에 대해 배우는 작업에 함께 모은다는 것입니다. 과거에 수행된 것에 의해 제한되지 않습니다. 이는 우리가 우리 자신의 전통에서 오지 않았지만, 우리만큼 데이터셋에 관심이 있는 사람들을 존중하기 위해 노력해야 함을 의미합니다. 데이터 과학은 다학제적이며 점점 더 중요해지고 있습니다. 따라서 우리 세상을 반영해야 합니다. 데이터 과학에는 다양한 배경, 접근 방식 및 분야가 필요합니다.\index{data science!diversity}

우리 세상은 지저분하며, 우리의 데이터도 마찬가지입니다. 데이터로 이야기를 성공적으로 전달하려면 프로세스가 어려울 것이라는 사실에 익숙해져야 합니다. 영국 수학자 한나 프라이는 문제를 해결하기 위해 코드를 다시 작성하는 데 6개월을 보냈다고 설명합니다 [@hannahfryft]. 여러분은 그것을 고수하는 법을 배워야 합니다. 또한 때로는 실패를 받아들여야 하며, 이는 회복력을 개발하고 내재적 동기를 가짐으로써 가능합니다. 데이터의 세계는 가능성과 확률을 고려하고, 그들 사이에서 절충하는 방법을 배우는 것입니다. 우리가 확실히 아는 것은 거의 없으며, 완벽한 분석은 없습니다.

궁극적으로, 우리는 모두 데이터를 사용하여 이야기를 전달할 뿐이지만, 이러한 이야기는 점점 더 세상에서 가장 중요한 이야기 중 하나가 되고 있습니다.

## 연습 문제

### 퀴즈 {.unnumbered}

1. 데이터 과학이란 무엇입니까 (자신의 말로)?
2.  @register2020 에 따르면, 데이터 결정은 (하나를 선택하십시오)?
    a. 실제 사람들에게 영향을 미칩니다.
    b. 아무에게도 영향을 미치지 않습니다.
    c. 훈련 세트에 있는 사람들에게 영향을 미칩니다.
    d. 테스트 세트에 있는 사람들에게 영향을 미칩니다.
3.  @keyes2019 에 따르면, 데이터 과학이란 무엇입니까 (하나를 선택하십시오)?
    a. 데이터 과학은 과학적 방법, 프로세스, 알고리즘 및 시스템을 사용하여 많은 구조화된 및 비구조화된 데이터에서 지식과 통찰력을 추출하는 학제 간 분야입니다.
    b. 의사 결정을 위한 대량의 데이터에 대한 양적 분석.
    c. 인간성을 셀 수 있는 것으로 비인간적으로 축소하는 것.
4.  @keyes2019 에 따르면, 표준화된 범주를 요구하는 데이터 시스템의 한 가지 결과는 무엇입니까 (하나를 선택하십시오)?
    a. 사용자 경험 저하.
    b. 보안 조치 손상.
    c. 기술 혁신 증가.
    d. 개인의 정체성과 경험의 말소.
5.  @kieranskitchen 에 따르면, 데이터를 다루는 것에 대한 일반적인 비판은 무엇입니까 (하나를 선택하십시오)?
    a. 너무 시간이 많이 걸리고 비효율적이라는 것.
    b. 숫자 뒤에 있는 인간 삶의 현실과 거리를 두게 한다는 것.
    c. 분석을 위해 값비싼 소프트웨어와 광범위한 훈련이 필요하다는 것.
6.  @kieranskitchen 에 따르면, 그 비판에 대한 한 가지 답변은 무엇입니까 (하나를 선택하십시오)?
    a. 데이터를 다루는 것은 의미에 대한 질문과 대면하게 합니다.
    b. 데이터 분석은 수행되어서는 안 됩니다.
    c. 데이터는 자동화된 프로세스에 의해서만 분석되어야 합니다.
    d. 질적 접근 방식이 지배적인 접근 방식이어야 합니다.
7.  @keyes2019 와 @kieranskitchen 을 어떻게 조화시킬 수 있습니까?
8.  윤리가 데이터 과학의 핵심 요소인 이유는 무엇입니까 (하나를 선택하십시오)?
    a. 데이터 과학은 항상 민감한 개인 정보를 포함하기 때문입니다.
    b. 윤리적 고려 사항이 분석을 더 쉽게 만들기 때문입니다.
    c. 데이터셋은 인간과 관련될 가능성이 높으며 맥락을 고려해야 하기 때문입니다.
    d. 규제가 모든 데이터 분석에 윤리 승인을 요구하기 때문입니다.
9.  이 장에서 설명된 @crawford 에 따르면, 다음 중 우리 세상과 따라서 우리의 데이터를 형성하는 힘은 무엇입니까 (모두 선택하십시오)?
    a. 정치적.
    b. 물리적.
    c. 역사적.
    d. 문화적.
    e. 사회적.
10. @nottomford 에 따르면, 컴파일러란 무엇입니까 (하나를 선택하십시오)?
    a. 파일에 입력한 기호를 하위 수준 명령으로 변환하는 소프트웨어.
    b. 누군가가 입력하거나 복사하거나 다른 곳에서 붙여넣은 일련의 기호 (일반적인 키보드 문자를 사용하여 어떤 종류의 파일로 저장됨).
    c. 이점이 있는 시계.
    d. 펀치 카드에 구멍을 뚫고, 상자에 넣고, 로드한 다음, 컴퓨터가 카드를 넘겨 구멍이 있는 곳을 식별하고 메모리 일부를 업데이트하는 것.
11. 성별에 대한 설문조사 결과가 다음과 같다고 가정해 봅시다: "남성: 879", "여성: 912", "논바이너리: 10", "말하고 싶지 않음: 3", "기타: 1". "말하고 싶지 않음"을 고려하는 적절한 방법은 무엇입니까 (하나를 선택하십시오)?
    a. 삭제합니다.
    b. 상황에 따라 다릅니다.
    c. 포함합니다.
    d. "기타"로 병합합니다.
12. 인종 및/또는 성별을 예측 변수로 포함하면 모델의 성능이 향상되는 직업을 가지고 있다고 가정해 봅시다. 분석에 이러한 변수를 포함할지 여부를 결정할 때 어떤 요소를 고려할 것입니까 (자신의 말로)?
13. 데이터 과학에서 재현성이란 무엇을 의미합니까 (하나를 선택하십시오)?
    a. 다른 데이터셋으로 유사한 결과를 생성할 수 있는 것.
    b. 분석의 모든 단계를 다른 사람이 독립적으로 다시 수행할 수 있도록 보장하는 것.
    c. 동료 심사 저널에 결과를 게시하는 것.
    d. 데이터를 보호하기 위해 독점 소프트웨어를 사용하는 것.
14. 측정과 관련된 과제는 무엇입니까 (하나를 선택하십시오)?
    a. 일반적으로 간단하고 거의 주의를 기울일 필요가 없습니다.
    b. 무엇을 어떻게 측정할지 결정하는 것은 복잡하고 맥락에 따라 다릅니다.
    c. 데이터 수집은 객관적이고 편향이 없습니다.
    d. 측정은 항상 정확하고 시간이 지나도 일관적입니다.
15. 조각가 비유에서 조각하는 행위는 데이터 워크플로우에서 무엇을 나타냅니까 (하나를 선택하십시오)?
    a. 데이터에 맞는 복잡한 모델을 생성하는 것.
    b. 원시 데이터를 획득하는 것.
    c. 필요한 데이터셋을 드러내기 위해 데이터를 정리하고 준비하는 것.
    d. 결과를 시각화하는 것.
16. 탐색적 데이터 분석(EDA)이 개방형 프로세스인 이유는 무엇입니까 (하나를 선택하십시오)?
    a. 따라야 할 고정된 단계가 있기 때문입니다.
    b. 데이터의 형태와 패턴을 이해하기 위해 지속적인 반복이 필요하기 때문입니다.
    c. 구조화된 방식으로 가설을 테스트하는 것을 포함하기 때문입니다.
    d. 자동화할 수 있기 때문입니다.
17. 통계 모델을 신중하게 사용해야 하는 이유는 무엇입니까 (하나를 선택하십시오)?
    a. 항상 결정적인 결과를 제공하기 때문입니다.
    b. 초기 단계에서 내려진 결정을 반영할 수 있기 때문입니다.
    c. 대부분의 청중에게 너무 복잡하기 때문입니다.
    d. 데이터가 잘 제시되면 불필요하기 때문입니다.
18. 키 측정의 어려움에 대해 생각하는 것에서 얻을 수 있는 한 가지 교훈은 무엇입니까 (하나를 선택하십시오)?
    a. 키는 변동성이 거의 없는 간단한 측정입니다.
    b. 모든 측정은 올바른 도구로 수행되면 정확합니다.
    c. 간단한 측정조차도 데이터 품질에 영향을 미치는 복잡성을 가질 수 있습니다.
    d. 키는 데이터 분석에서 유용한 변수가 아닙니다.
19. 데이터셋에서 누락된 사람을 고려하지 않는 것의 위험은 무엇입니까 (하나를 선택하십시오)?
    a. 분석에 큰 영향을 미치지 않습니다.
    b. 데이터 양을 줄여 분석을 단순화합니다.
    c. 전체 맥락을 나타내지 않는 결론으로 이어질 수 있습니다.
20. 통계 모델링의 목적은 무엇입니까 (하나를 선택하십시오)?
    a. 데이터를 탐색하고 이해하는 데 도움이 되는 도구.
    b. 가설을 증명하는 것.
    c. 탐색적 데이터 분석을 대체하는 것.
21. "우리 데이터는 지저분하고 복잡한 세상의 단순화이다"라는 말은 무엇을 의미합니까 (하나를 선택하십시오)?
    a. 데이터는 현실의 모든 측면을 완벽하게 포착합니다.
    b. 데이터는 분석을 가능하게 하기 위해 현실을 단순화하지만, 모든 세부 사항을 포착할 수는 없습니다.
    c. 데이터는 항상 부정확하고 쓸모없습니다.

### 수업 활동 {.unnumbered}

- 강사는 수업 사진을 찍은 다음 화면에 사진을 표시해야 합니다. 소그룹으로 학생들은 사진이 보여주는 세 가지 측면과 보여주지 않는 세 가지 측면을 식별해야 합니다. 이것이 데이터 과학과 어떻게 관련되는지 논의하십시오.
- 강사는 각 그룹에 측정에 사용할 다른 항목을 제공해야 합니다. 일부는 다른 것보다 더 유용합니다. 예를 들어, 줄자, 종이, 자, 마커, 저울 등. 그런 다음 학생들은 해당 항목을 사용하여 다음 질문에 답해야 합니다: "머리카락 길이는 얼마입니까?". 숫자를 스프레드시트에 추가하십시오. 스프레드시트만 있다면 머리카락 길이에 대해 무엇을 이해하고 무엇을 이해하지 못할 것입니까? 이를 더 넓은 데이터 과학과 연결하십시오.

### 과제 {.unnumbered}

이 과제의 목적은 겉보기에 간단해 보이는 것조차 측정의 어려움을 명확히 하고, 따라서 더 복잡한 영역에서 측정 문제의 가능성을 명확히 하는 것입니다.

무, 겨자잎, 루꼴라와 같이 빠르게 자라는 식물의 씨앗을 구하십시오. 씨앗을 심고 사용한 흙의 양을 측정하십시오. 물을 주고 사용한 물의 양을 측정하십시오. 매일 변화를 기록하십시오. 더 일반적으로, 가능한 한 많이 측정하고 기록하십시오. 측정의 어려움에 대한 생각을 기록하십시오. 결국 씨앗이 싹을 틔울 것이고, 어떻게 자라는지 측정해야 합니다.
